# routes/webhook.py

import collections
import threading
import time
import random
from datetime import datetime, timezone
from flask import Blueprint, request, jsonify
from typing import Optional, List
from gevent import spawn_later, spawn, sleep
from gevent.lock import Semaphore

import task_manager
import handler.emby as emby
import config_manager
import constants
import utils
import handler.telegram as telegram
import extensions
from extensions import SYSTEM_UPDATE_MARKERS, SYSTEM_UPDATE_LOCK, RECURSION_SUPPRESSION_WINDOW, DELETING_COLLECTIONS, UPDATING_IMAGES, UPDATING_METADATA
from core_processor import MediaProcessor
from tasks.watchlist import task_process_watchlist
from tasks.users import task_auto_sync_template_on_policy_change
from tasks.media import task_sync_all_metadata, task_sync_images
from handler.custom_collection import RecommendationEngine
from handler import tmdb_collections as collections_handler
from services.cover_generator import CoverGeneratorService
from database import custom_collection_db, tmdb_collection_db, settings_db, user_db, maintenance_db, media_db, queries_db, watchlist_db
from database.log_db import LogDBManager
from handler.tmdb import get_movie_details, get_tv_details
from handler.nullbr import SmartOrganizer, get_config, notify_cms_scan
from handler.p115_service import P115Service
try:
    from p115client import P115Client
except ImportError:
    P115Client = None
import logging
logger = logging.getLogger(__name__)

# åˆ›å»ºä¸€ä¸ªæ–°çš„è“å›¾
webhook_bp = Blueprint('webhook_bp', __name__)

# --- æ¨¡å—çº§å˜é‡ ---
WEBHOOK_BATCH_QUEUE = collections.deque()
WEBHOOK_BATCH_LOCK = threading.Lock()
WEBHOOK_BATCH_DEBOUNCE_TIME = 5
WEBHOOK_BATCH_DEBOUNCER = None

UPDATE_DEBOUNCE_TIMERS = {}
UPDATE_DEBOUNCE_LOCK = threading.Lock()
UPDATE_DEBOUNCE_TIME = 15
# --- è§†é¢‘æµé¢„æ£€å¸¸é‡ ---
STREAM_CHECK_MAX_RETRIES = 60   # æœ€å¤§é‡è¯•æ¬¡æ•° 
STREAM_CHECK_INTERVAL = 10      # æ¯æ¬¡è½®è¯¢é—´éš”(ç§’)
STREAM_CHECK_SEMAPHORE = Semaphore(5) # é™åˆ¶å¹¶å‘é¢„æ£€çš„æ•°é‡ï¼Œé˜²æ­¢å¤§é‡å…¥åº“æ—¶æŸ¥æŒ‚ Emby

def _handle_full_processing_flow(processor: 'MediaProcessor', item_id: str, force_full_update: bool, new_episode_ids: Optional[List[str]] = None, is_new_item: bool = True):
    """
    ã€Webhook ç»Ÿä¸€å…¥å£ã€‘
    ç»Ÿä¸€å¤„ç† æ–°å…¥åº“(New) å’Œ è¿½æ›´(Update) ä¸¤ç§æƒ…å†µã€‚
    """
    if not processor:
        logger.error(f"  ğŸš« å®Œæ•´å¤„ç†æµç¨‹ä¸­æ­¢ï¼šæ ¸å¿ƒå¤„ç†å™¨ (MediaProcessor) æœªåˆå§‹åŒ–ã€‚")
        return

    item_details = emby.get_emby_item_details(item_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id)
    if not item_details:
        logger.error(f"  ğŸš« æ— æ³•è·å–é¡¹ç›® {item_id} çš„è¯¦æƒ…ï¼Œä»»åŠ¡ä¸­æ­¢ã€‚")
        return
    
    item_name_for_log = item_details.get("Name", f"ID:{item_id}")
    item_type = item_details.get("Type")
    tmdb_id = item_details.get("ProviderIds", {}).get("Tmdb")

    # 1. æ ¸å¿ƒè°ƒç”¨ï¼šä¼˜å…ˆæ‰§è¡Œå…ƒæ•°æ®å¤„ç† (process_single_item)
    processed_successfully = processor.process_single_item(
        item_id, 
        force_full_update=force_full_update,
        specific_episode_ids=new_episode_ids 
    )
    
    if not processed_successfully:
        logger.warning(f"  âœ é¡¹ç›® '{item_name_for_log}' çš„å…ƒæ•°æ®å¤„ç†æœªæˆåŠŸå®Œæˆï¼Œè·³è¿‡åç»­æ­¥éª¤ã€‚")
        return

    # 2. æ™ºèƒ½è¿½å‰§åˆ¤æ–­ - åˆå§‹å…¥åº“
    if is_new_item and item_type == "Series":
        processor.check_and_add_to_watchlist(item_details)

    # 3. åç»­å¤„ç†
    if is_new_item:
        try:
            tmdb_id = item_details.get("ProviderIds", {}).get("Tmdb")
            item_name = item_details.get("Name", f"ID:{item_id}")
            
            # --- åŒ¹é… List (æ¦œå•) ç±»å‹çš„åˆé›† (ä¿æŒä¸å˜) ---
            # æ¦œå•ç±»åˆé›†æ˜¯é™æ€çš„ï¼Œéœ€è¦å°†æ–°å…¥åº“çš„é¡¹ç›®åŠ å…¥åˆ° Emby å®ä½“åˆé›†ä¸­
            if tmdb_id:
                updated_list_collections = custom_collection_db.match_and_update_list_collections_on_item_add(
                    new_item_tmdb_id=tmdb_id,
                    new_item_emby_id=item_id,
                    new_item_name=item_name
                )
                
                if updated_list_collections:
                    logger.info(f"  âœ ã€Š{item_name}ã€‹åŒ¹é…åˆ° {len(updated_list_collections)} ä¸ªæ¦œå•ç±»åˆé›†ï¼Œæ­£åœ¨è¿½åŠ ...")
                    for collection_info in updated_list_collections:
                        emby.append_item_to_collection(
                            collection_id=collection_info['emby_collection_id'],
                            item_emby_id=item_id,
                            base_url=processor.emby_url,
                            api_key=processor.emby_api_key,
                            user_id=processor.emby_user_id
                        )

            # â˜…â˜…â˜… ç§»é™¤ Filter ç±»åˆé›†çš„åŒ¹é…é€»è¾‘ â˜…â˜…â˜…
            # Filter ç±»åˆé›†ç°åœ¨æ˜¯åŸºäº SQL å®æ—¶æŸ¥è¯¢çš„ï¼Œä¸éœ€è¦åœ¨å…¥åº“æ—¶åšä»»ä½•æ“ä½œã€‚
            # åªè¦ media_metadata è¡¨æ›´æ–°äº†ï¼ˆprocess_single_item å·²å®Œæˆï¼‰ï¼ŒSQL æŸ¥è¯¢è‡ªç„¶èƒ½æŸ¥åˆ°å®ƒã€‚

        except Exception as e:
            logger.error(f"  âœ ä¸ºæ–°å…¥åº“é¡¹ç›® '{item_name_for_log}' åŒ¹é…æ¦œå•åˆé›†æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", exc_info=True)

        # --- å°é¢ç”Ÿæˆé€»è¾‘ (ä¿æŒä¸å˜) ---
        try:
            cover_config = settings_db.get_setting('cover_generator_config') or {}

            if cover_config.get("enabled") and cover_config.get("transfer_monitor"):
                # ... (è·å– library_info çš„é€»è¾‘) ...
                library_info = emby.get_library_root_for_item(item_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id)
                
                if library_info:
                    library_id = library_info.get("Id")
                    library_name = library_info.get("Name", library_id)
                    
                    if library_info.get('CollectionType') in ['movies', 'tvshows', 'boxsets', 'mixed', 'music']:
                        server_id = 'main_emby'
                        library_unique_id = f"{server_id}-{library_id}"
                        if library_unique_id not in cover_config.get("exclude_libraries", []):
                            # ... (è·å– item_count) ...
                            TYPE_MAP = {'movies': 'Movie', 'tvshows': 'Series', 'music': 'MusicAlbum', 'boxsets': 'BoxSet', 'mixed': 'Movie,Series'}
                            collection_type = library_info.get('CollectionType')
                            item_type_to_query = TYPE_MAP.get(collection_type)
                            item_count = 0
                            if library_id and item_type_to_query:
                                item_count = emby.get_item_count(base_url=processor.emby_url, api_key=processor.emby_api_key, user_id=processor.emby_user_id, parent_id=library_id, item_type=item_type_to_query) or 0

                            logger.info(f"  âœ æ­£åœ¨ä¸ºåª’ä½“åº“ '{library_name}' ç”Ÿæˆå°é¢ (å½“å‰å®æ—¶æ•°é‡: {item_count}) ---")
                            cover_service = CoverGeneratorService(config=cover_config)
                            cover_service.generate_for_library(emby_server_id=server_id, library=library_info, item_count=item_count)

            # â˜…â˜…â˜… ç§»é™¤ update_user_caches_on_item_add è°ƒç”¨ â˜…â˜…â˜…
            # æƒé™ç°åœ¨æ˜¯å®æ—¶çš„ï¼Œä¸éœ€è¦è¡¥ç¥¨äº†ã€‚

        except Exception as e:
            logger.error(f"  âœ åœ¨æ–°å…¥åº“åæ‰§è¡Œå°é¢ç”Ÿæˆæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)

        # ======================================================================
        # â˜…â˜…â˜…  TMDb åˆé›†è‡ªåŠ¨è¡¥å…¨ â˜…â˜…â˜…
        # ======================================================================
        try:
            # 1. æ£€æŸ¥ç±»å‹ (åªå¤„ç†ç”µå½±)
            # â˜…â˜…â˜… ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨ item_details å’Œ tmdb_idï¼Œä¸å†ä¾èµ– item_metadata â˜…â˜…â˜…
            current_type = item_details.get('Type')
            current_tmdb_id = tmdb_id  # è¿™ä¸ªå˜é‡åœ¨å‡½æ•°å‰é¢å·²ç»å®šä¹‰è¿‡äº†
            current_name = item_name   # è¿™ä¸ªå˜é‡åœ¨å‡½æ•°å‰é¢ä¹Ÿå®šä¹‰è¿‡äº†

            if current_type == 'Movie' and current_tmdb_id:
                # 2. æ£€æŸ¥å¼€å…³
                config = settings_db.get_setting('native_collections_config') or {}
                is_auto_complete_enabled = config.get('auto_complete_enabled', False)

                if is_auto_complete_enabled:
                    logger.trace(f"  âœ æ­£åœ¨æ£€æŸ¥ç”µå½± '{current_name}' æ‰€å± TMDb åˆé›†...")
                    # ç›´æ¥è°ƒç”¨ handler
                    collections_handler.check_and_subscribe_collection_from_movie(
                        movie_tmdb_id=str(current_tmdb_id),
                        movie_name=current_name,
                        movie_emby_id=item_id
                    )
        except Exception as e:
            logger.warning(f"  âœ æ£€æŸ¥æ‰€å± TMDb åˆé›†æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    logger.trace(f"  âœ Webhook ä»»åŠ¡åŠæ‰€æœ‰åç»­æµç¨‹å®Œæˆ: '{item_name_for_log}'")

    # 4. â˜…â˜…â˜… é€šçŸ¥åˆ†æµ â˜…â˜…â˜…
    try:
        # å¦‚æœæä¾›äº† new_episode_idsï¼Œè¯´æ˜æ˜¯è¿½æ›´é€šçŸ¥
        # å¦‚æœ is_new_item ä¸º Trueï¼Œè¯´æ˜æ˜¯æ–°å…¥åº“é€šçŸ¥
        notif_type = 'update' if (new_episode_ids and not is_new_item) else 'new'
        
        telegram.send_media_notification(
            item_details=item_details, 
            notification_type=notif_type, 
            new_episode_ids=new_episode_ids
        )
    except Exception as e:
        logger.error(f"è§¦å‘é€šçŸ¥å¤±è´¥: {e}")

    logger.trace(f"  âœ Webhook ä»»åŠ¡åŠæ‰€æœ‰åç»­æµç¨‹å®Œæˆ: '{item_name_for_log}'")

    # æ‰“æ ‡
    if is_new_item: 
        try:
            # 1. ä»æ•°æ®åº“è·å–æœ€æ–°è®°å½•
            db_record = media_db.get_media_details(str(tmdb_id), item_type)
            
            if db_record:
                # 2. æå– Library ID
                # asset_details_json æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªå³å¯
                assets = db_record.get('asset_details_json')
                lib_id = None
                if assets and isinstance(assets, list) and len(assets) > 0:
                    lib_id = assets[0].get('source_library_id')
                
                # 3. æå–ä¿®æ­£åçš„åˆ†çº§ (US)
                # official_rating_json: {"US": "XXX", "DE": "18"}
                ratings = db_record.get('official_rating_json')
                us_rating = None
                if ratings and isinstance(ratings, dict):
                    us_rating = ratings.get('US')
                
                if lib_id:
                    # æ—¢ç„¶æ•°æ®éƒ½åœ¨æ‰‹é‡Œäº†ï¼Œä¸éœ€è¦å»¶è¿Ÿï¼Œç›´æ¥å¹²ï¼
                    logger.info(f"  âœ [è‡ªåŠ¨æ‰“æ ‡] åŸºäºæ•°æ®åº“æœ€æ–°å…ƒæ•°æ® (åº“ID:{lib_id}, åˆ†çº§:{us_rating}) ...")
                    # è¿™é‡Œçš„ lib_name ä¼ ä¸ªå ä½ç¬¦å³å¯ï¼Œä¸å½±å“é€»è¾‘ï¼Œåªå½±å“æ—¥å¿—
                    _handle_immediate_tagging_with_lib(item_id, item_name_for_log, lib_id, "DB_Source", known_rating=us_rating)
                else:
                    logger.warning(f"  âœ [è‡ªåŠ¨æ‰“æ ‡] æ•°æ®åº“è®°å½•ä¸­æœªæ‰¾åˆ° æ¥æºåº“ï¼Œè·³è¿‡æ‰“æ ‡ã€‚")
            else:
                logger.warning(f"  âœ [è‡ªåŠ¨æ‰“æ ‡] æ— æ³•ä»æ•°æ®åº“è¯»å–åˆšå†™å…¥çš„è®°å½•ï¼Œè·³è¿‡æ‰“æ ‡ã€‚")

        except Exception as e:
            logger.warning(f"  âœ [è‡ªåŠ¨æ‰“æ ‡] è§¦å‘æ‰“æ ‡å¤±è´¥: {e}")

    # åˆ·æ–°æ™ºèƒ½è¿½å‰§çŠ¶æ€ 
    if item_type == "Series" and tmdb_id:
        def _async_trigger_watchlist():
            try:
                watching_ids = watchlist_db.get_watching_tmdb_ids()
                if str(tmdb_id) not in watching_ids:
                    logger.debug(f"  âœ [æ™ºèƒ½è¿½å‰§] å‰§é›† {tmdb_id} å½“å‰ä¸åœ¨è¿½å‰§åˆ—è¡¨ä¸­ (çŠ¶æ€é Watching)ï¼Œè·³è¿‡åˆ·æ–°ã€‚")
                    return
                # =======================================================

                logger.info(f"  âœ [æ™ºèƒ½è¿½å‰§] è§¦å‘å•é¡¹åˆ·æ–°...")
                task_manager.submit_task(
                    task_process_watchlist,
                    task_name=f"åˆ·æ–°æ™ºèƒ½è¿½å‰§: {item_name_for_log}",
                    processor_type='watchlist', 
                    tmdb_id=str(tmdb_id)
                )
            except Exception as e:
                logger.error(f"  ğŸš« è§¦å‘æ™ºèƒ½è¿½å‰§ä»»åŠ¡å¤±è´¥: {e}")

        # å¯åŠ¨åç¨‹ï¼Œä¸ç­‰å¾…ç»“æœï¼Œç›´æ¥è®©å½“å‰ Webhook ä»»åŠ¡ç»“æŸ
        spawn(_async_trigger_watchlist)

def _handle_immediate_tagging_with_lib(item_id, item_name, lib_id, lib_name, known_rating=None):
    """
    è‡ªåŠ¨æ‰“æ ‡ (æ”¯æŒåˆ†çº§è¿‡æ»¤)ã€‚
    å¢åŠ  known_rating å‚æ•°ï¼šå¦‚æœè°ƒç”¨æ–¹å·²ç»çŸ¥é“ç¡®åˆ‡åˆ†çº§ï¼ˆå¦‚ä»æ•°æ®åº“æŸ¥åˆ°çš„ï¼‰ï¼Œç›´æ¥ä½¿ç”¨ï¼Œä¸å†æŸ¥è¯¢ Embyã€‚
    """
    try:
        processor = extensions.media_processor_instance
        tagging_config = settings_db.get_setting('auto_tagging_rules') or []
        
        # åªæœ‰å½“æ²¡æœ‰ä¼ å…¥ known_rating æ—¶ï¼Œæ‰éœ€è¦å» Emby æŸ¥
        item_details = None 
        
        for rule in tagging_config:
            target_libs = rule.get('library_ids', [])
            if not target_libs or lib_id in target_libs:
                tags = rule.get('tags', [])
                rating_filters = rule.get('rating_filters', [])
                
                if tags:
                    # â˜…â˜…â˜… æ ¸å¿ƒä¿®æ”¹ï¼šåˆ†çº§åŒ¹é…é€»è¾‘ â˜…â˜…â˜…
                    if rating_filters:
                        # 1. ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„å·²çŸ¥åˆ†çº§ (æ•°æ®åº“é‡Œçš„çœŸç†)
                        current_rating = known_rating
                        
                        # 2. å¦‚æœæ²¡ä¼ ï¼Œä¸”è¿˜æ²¡æŸ¥è¿‡ Embyï¼Œåˆ™å»æŸ¥ (å…œåº•é€»è¾‘)
                        if not current_rating and item_details is None:
                            item_details = emby.get_emby_item_details(
                                item_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id,
                                fields="OfficialRating"
                            )
                            if item_details:
                                current_rating = item_details.get('OfficialRating')
                        
                        # 3. æ‰§è¡ŒåŒ¹é…
                        if not current_rating:
                            continue # æ‹¿ä¸åˆ°åˆ†çº§ï¼Œè·³è¿‡
                            
                        target_codes = queries_db._expand_rating_labels(rating_filters)
                        
                        # å…¼å®¹ "US: XXX" å’Œ "XXX" ä¸¤ç§æ ¼å¼
                        rating_code = current_rating.split(':')[-1].strip()
                        
                        if rating_code not in target_codes:
                            logger.debug(f"  ğŸ·ï¸ åª’ä½“é¡¹ '{item_name}' åˆ†çº§ '{current_rating}' ä¸æ»¡è¶³è§„åˆ™é™åˆ¶ {rating_filters}ï¼Œè·³è¿‡æ‰“æ ‡ã€‚")
                            continue

                    if rating_filters:
                        rule_desc = f"åˆ†çº§ '{','.join(rating_filters)}'"
                    else:
                        rule_desc = f"åº“ '{lib_name}'"

                    logger.info(f"  ğŸ·ï¸ åª’ä½“é¡¹ '{item_name}' å‘½ä¸­ {rule_desc} è§„åˆ™ï¼Œè¿½åŠ æ ‡ç­¾: {tags}")
                    emby.add_tags_to_item(item_id, tags, processor.emby_url, processor.emby_api_key, processor.emby_user_id)
                
                break 
    except Exception as e:
        logger.error(f"  ğŸš« [è‡ªåŠ¨æ‰“æ ‡] å¤±è´¥: {e}")

# --- è¾…åŠ©å‡½æ•° ---
def _process_batch_webhook_events():
    global WEBHOOK_BATCH_DEBOUNCER
    with WEBHOOK_BATCH_LOCK:
        items_in_batch = list(set(WEBHOOK_BATCH_QUEUE))
        WEBHOOK_BATCH_QUEUE.clear()
        WEBHOOK_BATCH_DEBOUNCER = None

    if not items_in_batch:
        return

    logger.info(f"  âœ é˜²æŠ–è®¡æ—¶å™¨åˆ°æœŸï¼Œå¼€å§‹æ‰¹é‡å¤„ç† {len(items_in_batch)} ä¸ª Emby Webhook æ–°å¢/å…¥åº“äº‹ä»¶ã€‚")

    parent_items = collections.defaultdict(lambda: {
        "name": "", "type": "", "episode_ids": set()
    })
    
    for item_id, item_name, item_type in items_in_batch:
        parent_id = item_id
        parent_name = item_name
        parent_type = item_type
        
        if item_type == "Episode":
            series_id = emby.get_series_id_from_child_id(
                item_id, extensions.media_processor_instance.emby_url,
                extensions.media_processor_instance.emby_api_key, extensions.media_processor_instance.emby_user_id, item_name=item_name
            )
            if not series_id:
                logger.warning(f"  âœ æ‰¹é‡å¤„ç†ä¸­ï¼Œåˆ†é›† '{item_name}' æœªæ‰¾åˆ°æ‰€å±å‰§é›†ï¼Œè·³è¿‡ã€‚")
                continue
            
            parent_id = series_id
            parent_type = "Series"
            
            # å°†å…·ä½“çš„åˆ†é›†IDæ·»åŠ åˆ°è®°å½•ä¸­
            parent_items[parent_id]["episode_ids"].add(item_id)
            
            # æ›´æ–°çˆ¶é¡¹çš„åå­—ï¼ˆåªéœ€ä¸€æ¬¡ï¼‰
            if not parent_items[parent_id]["name"]:
                series_details = emby.get_emby_item_details(parent_id, extensions.media_processor_instance.emby_url, extensions.media_processor_instance.emby_api_key, extensions.media_processor_instance.emby_user_id, fields="Name")
                parent_items[parent_id]["name"] = series_details.get("Name", item_name) if series_details else item_name
        else:
            # å¦‚æœäº‹ä»¶æ˜¯ç”µå½±æˆ–å‰§é›†å®¹å™¨æœ¬èº«ï¼Œä¹Ÿè®°å½•ä¸‹æ¥
            parent_items[parent_id]["name"] = parent_name
        
        # æ›´æ–°çˆ¶é¡¹çš„ç±»å‹
        parent_items[parent_id]["type"] = parent_type

    logger.info(f"  âœ æ‰¹é‡äº‹ä»¶å»é‡åï¼Œå°†ä¸º {len(parent_items)} ä¸ªç‹¬ç«‹åª’ä½“é¡¹åˆ†æ´¾ä»»åŠ¡ã€‚")

    for parent_id, item_info in parent_items.items():
        parent_name = item_info['name']
        parent_type = item_info['type']
        episode_ids = list(item_info["episode_ids"])
        
        # 1. æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
        is_already_processed = parent_id in extensions.media_processor_instance.processed_items_cache

        # 2. æ£€æŸ¥æ•°æ®åº“æ˜¯å¦åœ¨çº¿ (å¤„ç†â€œåƒµå°¸æ•°æ®â€)
        if is_already_processed:
            # è¿™ä¸€æ­¥å¾ˆå¿«ï¼Œåªæ˜¯æŸ¥ä¸€ä¸‹ media_metadata è¡¨çš„ in_library å­—æ®µ
            is_online_in_db = media_db.is_emby_id_in_library(parent_id)
            
            # â˜…â˜…â˜… ä¼˜åŒ–æ ¸å¿ƒï¼šå¦‚æœä¸åœ¨çº¿ï¼Œç›´æ¥è¸¢å‡ºç¼“å­˜ï¼Œè§†ä¸ºæ–°é¡¹ç›®é‡è·‘ â˜…â˜…â˜…
            if not is_online_in_db:
                logger.info(f"  âœ âš ï¸ ç¼“å­˜å‘½ä¸­ '{parent_name}'ï¼Œä½†æ•°æ®åº“æ ‡è®°ä¸ºç¦»çº¿/ç¼ºå¤±ã€‚æ¸…é™¤ç¼“å­˜ï¼Œè§¦å‘é‡æ–°å…¥åº“æµç¨‹ã€‚")
                
                # ä»å†…å­˜ç¼“å­˜ä¸­ç§»é™¤
                if parent_id in extensions.media_processor_instance.processed_items_cache:
                    del extensions.media_processor_instance.processed_items_cache[parent_id]
                
                # æ ‡è®°ä¸ºæœªå¤„ç†ï¼Œåç»­é€»è¾‘ä¼šæŠŠå®ƒå½“ä½œâ€œæ–°å…¥åº“â€æ¥æ‰§è¡Œå®Œæ•´çš„æ•°æ®åº“ä¿®å¤
                is_already_processed = False
        # 3. ç»Ÿä¸€åˆ†æ´¾ä»»åŠ¡
        task_name_prefix = "Webhookè¿½æ›´" if is_already_processed and episode_ids else "Webhookå…¥åº“"
        
        logger.info(f"  âœ ä¸º '{parent_name}' åˆ†æ´¾ä»»åŠ¡: {task_name_prefix} (åˆ†é›†æ•°: {len(episode_ids)})")
        
        task_manager.submit_task(
            _handle_full_processing_flow,
            task_name=f"{task_name_prefix}: {parent_name}",
            processor_type='media', # ç¡®ä¿ä¼ é€’ processor å®ä¾‹
            item_id=parent_id,
            force_full_update=False, # Webhook è§¦å‘é€šå¸¸ä¸éœ€è¦å¼ºåˆ¶æ·±åº¦åˆ·æ–° TMDb
            new_episode_ids=episode_ids if episode_ids else None,
            is_new_item=not is_already_processed
        )

    logger.info("  âœ æ‰€æœ‰ Webhook æ‰¹é‡ä»»åŠ¡å·²æˆåŠŸåˆ†æ´¾ã€‚")

def _trigger_metadata_update_task(item_id, item_name):
    """è§¦å‘å…ƒæ•°æ®åŒæ­¥ä»»åŠ¡"""
    logger.info(f"  âœ é˜²æŠ–è®¡æ—¶å™¨åˆ°æœŸï¼Œä¸º '{item_name}' (ID: {item_id}) æ‰§è¡Œå…ƒæ•°æ®ç¼“å­˜åŒæ­¥ä»»åŠ¡ã€‚")
    task_manager.submit_task(
        task_sync_all_metadata,
        task_name=f"å…ƒæ•°æ®åŒæ­¥: {item_name}",
        processor_type='media',
        item_id=item_id,
        item_name=item_name
    )

def _trigger_images_update_task(item_id, item_name, update_description, sync_timestamp_iso):
    """è§¦å‘å›¾ç‰‡å¤‡ä»½ä»»åŠ¡"""
    logger.info(f"  âœ é˜²æŠ–è®¡æ—¶å™¨åˆ°æœŸï¼Œä¸º '{item_name}' (ID: {item_id}) æ‰§è¡Œå›¾ç‰‡å¤‡ä»½ä»»åŠ¡ã€‚")
    task_manager.submit_task(
        task_sync_images,
        task_name=f"å›¾ç‰‡å¤‡ä»½: {item_name}",
        processor_type='media',
        item_id=item_id,
        update_description=update_description,
        sync_timestamp_iso=sync_timestamp_iso
    )

def _enqueue_webhook_event(item_id, item_name, item_type):
    """
    å°†äº‹ä»¶åŠ å…¥æ‰¹é‡å¤„ç†é˜Ÿåˆ—ï¼Œå¹¶ç®¡ç†é˜²æŠ–è®¡æ—¶å™¨ã€‚
    """
    global WEBHOOK_BATCH_DEBOUNCER
    with WEBHOOK_BATCH_LOCK:
        WEBHOOK_BATCH_QUEUE.append((item_id, item_name, item_type))
        logger.debug(f"  âœ [é˜Ÿåˆ—] é¡¹ç›® '{item_name}' ({item_type}) å·²åŠ å…¥å¤„ç†é˜Ÿåˆ—ã€‚å½“å‰ç§¯å‹: {len(WEBHOOK_BATCH_QUEUE)}")
        
        if WEBHOOK_BATCH_DEBOUNCER is None or WEBHOOK_BATCH_DEBOUNCER.ready():
            logger.info(f"  âœ [é˜Ÿåˆ—] å¯åŠ¨æ‰¹é‡å¤„ç†è®¡æ—¶å™¨ï¼Œå°†åœ¨ {WEBHOOK_BATCH_DEBOUNCE_TIME} ç§’åæ‰§è¡Œã€‚")
            WEBHOOK_BATCH_DEBOUNCER = spawn_later(WEBHOOK_BATCH_DEBOUNCE_TIME, _process_batch_webhook_events)
        else:
            logger.debug("  âœ [é˜Ÿåˆ—] æ‰¹é‡å¤„ç†è®¡æ—¶å™¨è¿è¡Œä¸­ï¼Œç­‰å¾…åˆå¹¶ã€‚")

def _wait_for_stream_data_and_enqueue(item_id, item_name, item_type):
    """
    é¢„æ£€è§†é¢‘æµæ•°æ®ã€‚
    """
    if item_type not in ['Movie', 'Episode']:
        _enqueue_webhook_event(item_id, item_name, item_type)
        return

    logger.info(f"  âœ [é¢„æ£€] å¼€å§‹æ£€æŸ¥ '{item_name}' (ID:{item_id}) çš„è§†é¢‘æµæ•°æ®...")

    app_config = config_manager.APP_CONFIG
    emby_url = app_config.get("emby_server_url")
    emby_key = app_config.get("emby_api_key")
    emby_user_id = extensions.media_processor_instance.emby_user_id

    for i in range(STREAM_CHECK_MAX_RETRIES):
        try:
            item_details = None
            
            with STREAM_CHECK_SEMAPHORE:
                item_details = emby.get_emby_item_details(
                    item_id=item_id,
                    emby_server_url=emby_url,
                    emby_api_key=emby_key,
                    user_id=emby_user_id,
                    fields="MediaSources"
                )

            if not item_details:
                logger.warning(f"  âœ [é¢„æ£€] æ— æ³•è·å– '{item_name}' è¯¦æƒ…ï¼Œå¯èƒ½å·²è¢«åˆ é™¤ã€‚åœæ­¢ç­‰å¾…ã€‚")
                return

            media_sources = item_details.get("MediaSources", [])
            has_valid_video_stream = False
            
            if media_sources:
                for source in media_sources:
                    media_streams = source.get("MediaStreams", [])
                    for stream in media_streams:
                        if stream.get("Type") == "Video":
                            w = stream.get("Width")
                            h = stream.get("Height")
                            c = stream.get("Codec")
                            
                            # è°ƒç”¨ utils.check_stream_validity (å¿…é¡» Width>0 AND Codecæœ‰æ•ˆ)
                            is_valid, _ = utils.check_stream_validity(w, h, c)
                            
                            if is_valid:
                                has_valid_video_stream = True
                                break
                    if has_valid_video_stream:
                        break
            
            if has_valid_video_stream:
                logger.info(f"  âœ [é¢„æ£€] æˆåŠŸæ£€æµ‹åˆ° '{item_name}' çš„è§†é¢‘æµæ•°æ® (è€—æ—¶: {i * STREAM_CHECK_INTERVAL}s)ï¼ŒåŠ å…¥é˜Ÿåˆ—ã€‚")
                _enqueue_webhook_event(item_id, item_name, item_type)
                return
            
            logger.debug(f"  âœ [é¢„æ£€] '{item_name}' æš‚æ— è§†é¢‘æµæ•°æ®ï¼Œç­‰å¾…é‡è¯• ({i+1}/{STREAM_CHECK_MAX_RETRIES})...")
            sleep(STREAM_CHECK_INTERVAL + random.uniform(0, 2))

        except Exception as e:
            logger.error(f"  âœ [é¢„æ£€] æ£€æŸ¥ '{item_name}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            sleep(STREAM_CHECK_INTERVAL + random.uniform(0, 2))

    # è¶…æ—¶å¼ºåˆ¶å…¥åº“
    logger.warning(f"  âœ [é¢„æ£€] è¶…æ—¶ï¼åœ¨ {STREAM_CHECK_MAX_RETRIES * STREAM_CHECK_INTERVAL} ç§’å†…æœªæå–åˆ° '{item_name}' çš„è§†é¢‘æµæ•°æ®ã€‚å¼ºåˆ¶åŠ å…¥é˜Ÿåˆ—ã€‚")
    _enqueue_webhook_event(item_id, item_name, item_type)

# --- Webhook è·¯ç”± ---
@webhook_bp.route('/webhook/emby', methods=['POST'])
@extensions.processor_ready_required
def emby_webhook():
    data = request.json
    # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
    # â˜…â˜…â˜…            é­”æ³•æ—¥å¿— - START            â˜…â˜…â˜…
    # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
    # try:
    #     import json
    #     # ä½¿ç”¨ WARNING çº§åˆ«å’Œé†’ç›®çš„ emojiï¼Œè®©å®ƒåœ¨æ—¥å¿—ä¸­è„±é¢–è€Œå‡º
    #     logger.warning("âœ¨âœ¨âœ¨ [é­”æ³•æ—¥å¿—] æ”¶åˆ°åŸå§‹ Emby Webhook è´Ÿè½½ï¼Œå†…å®¹å¦‚ä¸‹: âœ¨âœ¨âœ¨")
    #     # å°†æ•´ä¸ª JSON æ•°æ®æ ¼å¼åŒ–åæ‰“å°å‡ºæ¥
    #     logger.warning(json.dumps(data, indent=2, ensure_ascii=False))
    # except Exception as e:
    #     logger.error(f"[é­”æ³•æ—¥å¿—] è®°å½•åŸå§‹ Webhook æ—¶å‡ºé”™: {e}")
    # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
    # â˜…â˜…â˜…             é­”æ³•æ—¥å¿— - END             â˜…â˜…â˜…
    # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
    event_type = data.get("Event") # Emby
    mp_event_type = data.get("type") # MP
    # ======================================================================
    # â˜…â˜…â˜… å¤„ç† MoviePilot transfer.complete äº‹ä»¶ â˜…â˜…â˜…
    # ======================================================================
    if mp_event_type == "transfer.complete":
        # 1. æ£€æŸ¥é…ç½®æ˜¯å¦å¼€å¯äº†æ™ºèƒ½æ•´ç†
        nb_config = get_config()
        if not nb_config.get('enable_smart_organize', False):
            logger.debug("  ğŸš« æ™ºèƒ½æ•´ç†æœªå¼€å¯ï¼Œå¿½ç•¥ MP é€šçŸ¥ã€‚")
            return jsonify({"status": "ignored_smart_organize_disabled"}), 200
        else:
            logger.info("  ğŸ“¥ æ”¶åˆ° MoviePilot ä¸Šä¼ å®Œæˆé€šçŸ¥ï¼Œå¼€å§‹æ¥ç®¡æ•´ç†...")

        # 2. æå–å…³é”®æ•°æ®
        try:
            transfer_info = data.get("data", {}).get("transferinfo", {})
            media_info = data.get("data", {}).get("mediainfo", {})
            
            # 115 æ–‡ä»¶ ID å’Œ æ–‡ä»¶å
            target_item = transfer_info.get("target_item", {})
            file_id = target_item.get("fileid")
            
            # 115 å½“å‰çˆ¶ç›®å½• ID (MP åˆ›å»ºçš„ä¸´æ—¶ç›®å½•)
            target_dir = transfer_info.get("target_diritem", {})
            current_parent_cid = target_dir.get("fileid")
            
            # å…ƒæ•°æ®
            tmdb_id = media_info.get("tmdb_id")
            media_type_cn = media_info.get("type") 
            title = media_info.get("title")
            
            if not file_id or not tmdb_id:
                logger.warning("  âš ï¸ MP é€šçŸ¥ç¼ºå°‘ fileid æˆ– tmdb_idï¼Œæ— æ³•å¤„ç†ã€‚")
                return jsonify({"status": "ignored_missing_data"}), 200

            # è½¬æ¢åª’ä½“ç±»å‹
            media_type = 'tv' if media_type_cn == 'ç”µè§†å‰§' else 'movie'
            
            # 3. è·å–å…±äº« 115 å®¢æˆ·ç«¯
            client = P115Service.get_client()
            if not client:
                return jsonify({"status": "error_no_p115_client"}), 500
                
            # 4. åˆå§‹åŒ–æ™ºèƒ½æ•´ç†å™¨
            organizer = SmartOrganizer(client, tmdb_id, media_type, title)
            
            # 5. è®¡ç®—ç›®æ ‡åˆ†ç±» CID
            target_cid = organizer.get_target_cid()
            
            if target_cid:
                logger.info(f"  ğŸš€ [MPä¸Šä¼ ] æ–°æ–‡ä»¶: {target_item.get('name')} (æ–‡ä»¶å¤§å°: {int(target_item.get('size', 0))/1024/1024:.2f} MB)")
                
                # æ„é€ çœŸå®çš„æ–‡ä»¶å¯¹è±¡ (æ¨¡æ‹Ÿ 115 API è¿”å›çš„ç»“æ„)
                real_root_item = {
                    'n': target_item.get("name"),
                    's': target_item.get("size"), # ç›´æ¥ç”¨ MP ç»™çš„å¤§å°
                    'cid': current_parent_cid,    # çˆ¶ç›®å½• ID
                    'fid': file_id                # â˜…â˜…â˜… å…³é”®ï¼šå¿…é¡»æœ‰ fidï¼Œexecute æ‰ä¼šè®¤ä¸ºæ˜¯å•æ–‡ä»¶æ¨¡å¼ â˜…â˜…â˜…
                }
                
                # åŒé‡ä¿é™©ï¼šå¦‚æœ MP ä¼ çš„æ˜¯æ–‡ä»¶å¤¹ (type=0)ï¼Œåˆ™ç§»é™¤ fid
                # ä½†é€šå¸¸ MP è½¬å­˜çš„éƒ½æ˜¯è§†é¢‘æ–‡ä»¶ï¼Œè¿™é‡Œä¸ºäº†é˜²æ­¢ä¸‡ä¸€
                if str(target_item.get("type")) == "0":
                    logger.warning("  âš ï¸ æ£€æµ‹åˆ° MP ä¸Šä¼ çš„æ˜¯æ–‡ä»¶å¤¹ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´é€’å½’æ‰«æï¼Œè¯·è°¨æ…ï¼")
                    del real_root_item['fid']
                    real_root_item['cid'] = file_id # æ–‡ä»¶å¤¹è‡ªå·±çš„ ID

                # logger.info(f"  ğŸš€ [MPä¸Šä¼ ] è½¬äº¤ SmartOrganizer.execute å¤„ç†...")
                # å¤ç”¨ execute é€»è¾‘
                success = organizer.execute(real_root_item, target_cid)
                
                if success:
                    # å¼ºåˆ¶åˆ é™¤ MP ä¸´æ—¶ç›®å½•
                    if current_parent_cid and str(current_parent_cid) != '0':
                        try:
                            logger.debug(f"  ğŸ§¹ [MPä¸Šä¼ ] åˆ é™¤ä¸´æ—¶ç›®å½•")
                            client.fs_delete([current_parent_cid])
                        except Exception as e:
                            logger.warning(f"  âš ï¸ æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")

                    logger.info("  ğŸ“£ [MPä¸Šä¼ ] æ•´ç†å®Œæˆï¼Œé€šçŸ¥ CMS æ‰§è¡Œå¢é‡åŒæ­¥...")
                    notify_cms_scan()
                    return jsonify({"status": "success_organized"}), 200
                else:
                    return jsonify({"status": "failed_organize"}), 500

            else:
                logger.info("  ğŸš« [MPä¸Šä¼ ] æœªå‘½ä¸­ä»»ä½•åˆ†ç±»è§„åˆ™ï¼Œä¿æŒåŸæ ·ã€‚")
                return jsonify({"status": "ignored_no_rule_match"}), 200

        except Exception as e:
            logger.error(f"  âŒ [MPä¸Šä¼ ] å¤„ç†å¤±è´¥: {e}", exc_info=True)
            return jsonify({"status": "error", "message": str(e)}), 500
        
    logger.debug(f"  âœ æ”¶åˆ°Emby Webhook: {event_type}")

    USER_DATA_EVENTS = [
        "item.markfavorite", "item.unmarkfavorite",
        "item.markplayed", "item.markunplayed",
        "playback.start", "playback.pause", "playback.stop",
        "item.rate"
    ]

    if event_type == "user.policyupdated":
        updated_user = data.get("User", {})
        updated_user_id = updated_user.get("Id")
        updated_user_name = updated_user.get("Name", "æœªçŸ¥ç”¨æˆ·")
        
        if not updated_user_id:
            return jsonify({"status": "event_ignored_no_user_id"}), 200

        # --- ç«‹å³åæŸ¥å¹¶æ›´æ–°æœ¬åœ° Policy ---
        try:
            def _update_local_policy_task():
                try:
                    # è·å–æœ€æ–°è¯¦æƒ…
                    user_details = emby.get_user_details(
                        updated_user_id, 
                        config_manager.APP_CONFIG.get("emby_server_url"), 
                        config_manager.APP_CONFIG.get("emby_api_key")
                    )
                    if user_details and 'Policy' in user_details:
                        # æ›´æ–°æ•°æ®åº“
                        user_db.upsert_emby_users_batch([user_details])
                        logger.info(f"  âœ Webhook: å·²æ›´æ–°ç”¨æˆ· {updated_user_id} çš„æœ¬åœ°æƒé™ç¼“å­˜ã€‚")
                except Exception as e:
                    logger.error(f"  âœ Webhook æ›´æ–°æœ¬åœ° Policy å¤±è´¥: {e}")

            # å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ Webhook è¿”å›
            spawn(_update_local_policy_task)
        except Exception as e:
            logger.error(f"å¯åŠ¨ Policy æ›´æ–°ä»»åŠ¡å¤±è´¥: {e}")

        # â˜…â˜…â˜… æ ¸å¿ƒé€»è¾‘: åœ¨å¤„ç†å‰ï¼Œå…ˆæ£€æŸ¥ä¿¡å·æ—— â˜…â˜…â˜…
        with SYSTEM_UPDATE_LOCK:
            last_update_time = SYSTEM_UPDATE_MARKERS.get(updated_user_id)
            # å¦‚æœæ‰¾åˆ°äº†æ ‡è®°ï¼Œå¹¶ä¸”æ—¶é—´æˆ³åœ¨æˆ‘ä»¬çš„æŠ‘åˆ¶çª—å£æœŸå†…
            if last_update_time and (time.time() - last_update_time) < RECURSION_SUPPRESSION_WINDOW:
                logger.debug(f"  âœ å¿½ç•¥ç”±ç³»ç»Ÿå†…éƒ¨åŒæ­¥è§¦å‘çš„ç”¨æˆ· '{updated_user_name}' çš„æƒé™æ›´æ–° Webhookã€‚")
                # ä¸ºäº†ä¿é™©èµ·è§ï¼Œç”¨å®Œå°±åˆ æ‰è¿™ä¸ªæ ‡è®°
                del SYSTEM_UPDATE_MARKERS[updated_user_id]
                # ç›´æ¥è¿”å›æˆåŠŸï¼Œä¸å†åˆ›å»ºä»»ä½•åå°ä»»åŠ¡
                return jsonify({"status": "event_ignored_system_triggered"}), 200
        
        # å¦‚æœä¸Šé¢çš„æ£€æŸ¥é€šè¿‡äº†ï¼ˆå³è¿™æ˜¯ä¸€ä¸ªæ­£å¸¸çš„æ‰‹åŠ¨æ“ä½œï¼‰ï¼Œæ‰ç»§ç»­æ‰§è¡ŒåŸæ¥çš„é€»è¾‘
        logger.info(f"  âœ æ£€æµ‹åˆ°ç”¨æˆ· '{updated_user_name}' çš„æƒé™ç­–ç•¥å·²æ›´æ–°ï¼Œå°†åˆ†æ´¾åå°ä»»åŠ¡æ£€æŸ¥æ¨¡æ¿åŒæ­¥ã€‚")
        task_manager.submit_task(
            task_auto_sync_template_on_policy_change,
            task_name=f"è‡ªåŠ¨åŒæ­¥æƒé™ (æº: {updated_user_name})",
            processor_type='media',
            updated_user_id=updated_user_id
        )
        return jsonify({"status": "auto_sync_task_submitted"}), 202

    if event_type in USER_DATA_EVENTS:
        user_from_webhook = data.get("User", {})
        user_id = user_from_webhook.get("Id")
        user_name = user_from_webhook.get("Name")
        user_name_for_log = user_name or user_id
        item_from_webhook = data.get("Item", {})
        item_id_from_webhook = item_from_webhook.get("Id")
        item_type_from_webhook = item_from_webhook.get("Type")

        if not user_id or not item_id_from_webhook:
            return jsonify({"status": "event_ignored_missing_data"}), 200

        id_to_update_in_db = None
        if item_type_from_webhook in ['Movie', 'Series']:
            id_to_update_in_db = item_id_from_webhook
        elif item_type_from_webhook == 'Episode':
            series_id = emby.get_series_id_from_child_id(
                item_id=item_id_from_webhook,
                base_url=config_manager.APP_CONFIG.get("emby_server_url"),
                api_key=config_manager.APP_CONFIG.get("emby_api_key"),
                user_id=user_id
            )
            if series_id:
                id_to_update_in_db = series_id
        
        if not id_to_update_in_db:
            return jsonify({"status": "event_ignored_unsupported_type_or_not_found"}), 200

        update_data = {"user_id": user_id, "item_id": id_to_update_in_db}
        
        if event_type in ["item.markfavorite", "item.unmarkfavorite", "item.markplayed", "item.markunplayed", "item.rate"]:
            user_data_from_item = item_from_webhook.get("UserData", {})
            if 'IsFavorite' in user_data_from_item:
                update_data['is_favorite'] = user_data_from_item['IsFavorite']
            if 'Played' in user_data_from_item:
                update_data['played'] = user_data_from_item['Played']
                if user_data_from_item['Played']:
                    update_data['playback_position_ticks'] = 0
                    update_data['last_played_date'] = datetime.now(timezone.utc)

        elif event_type in ["playback.start", "playback.pause", "playback.stop"]:
            playback_info = data.get("PlaybackInfo", {})
            if playback_info:
                position_ticks = playback_info.get('PositionTicks')
                if position_ticks is not None:
                    update_data['playback_position_ticks'] = position_ticks
                
                update_data['last_played_date'] = datetime.now(timezone.utc)
                
                if event_type == "playback.stop":
                    if playback_info.get('PlayedToCompletion') is True:
                        update_data['played'] = True
                        update_data['playback_position_ticks'] = 0
                    else:
                        update_data['played'] = False

        try:
            if len(update_data) > 2:
                user_db.upsert_user_media_data(update_data)
                item_name_for_log = f"ID:{id_to_update_in_db}"
                try:
                    # ä¸ºäº†æ—¥å¿—ï¼Œåªè¯·æ±‚ Name å­—æ®µï¼Œæé«˜æ•ˆç‡
                    item_details_for_log = emby.get_emby_item_details(
                        item_id=id_to_update_in_db,
                        emby_server_url=config_manager.APP_CONFIG.get("emby_server_url"),
                        emby_api_key=config_manager.APP_CONFIG.get("emby_api_key"),
                        user_id=user_id,
                        fields="Name"
                    )
                    if item_details_for_log and item_details_for_log.get("Name"):
                        item_name_for_log = item_details_for_log.get("Name")
                except Exception:
                    # å¦‚æœè·å–å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼Œæ—¥å¿—ä¸­ç»§ç»­ä½¿ç”¨ID
                    pass
                logger.trace(f"  âœ Webhook: å·²æ›´æ–°ç”¨æˆ· '{user_name_for_log}' å¯¹é¡¹ç›® '{item_name_for_log}' çš„çŠ¶æ€ ({event_type})ã€‚")
                return jsonify({"status": "user_data_updated"}), 200
            else:
                logger.debug(f"  âœ Webhook '{event_type}' æœªåŒ…å«å¯æ›´æ–°çš„ç”¨æˆ·æ•°æ®ï¼Œå·²å¿½ç•¥ã€‚")
                return jsonify({"status": "event_ignored_no_updatable_data"}), 200
        except Exception as e:
            logger.error(f"  âœ é€šè¿‡ Webhook æ›´æ–°ç”¨æˆ·åª’ä½“æ•°æ®æ—¶å¤±è´¥: {e}", exc_info=True)
            return jsonify({"status": "error_updating_user_data"}), 500

    trigger_events = ["item.add", "library.new", "library.deleted", "metadata.update", "image.update", "collection.items.removed", "None"]
    if event_type not in trigger_events:
        logger.debug(f"  âœ Webhookäº‹ä»¶ '{event_type}' ä¸åœ¨è§¦å‘åˆ—è¡¨ {trigger_events} ä¸­ï¼Œå°†è¢«å¿½ç•¥ã€‚")
        return jsonify({"status": "event_ignored_not_in_trigger_list"}), 200
    
    item_from_webhook = data.get("Item", {}) if data else {}
    original_item_id = item_from_webhook.get("Id")
    original_item_type = item_from_webhook.get("Type")
    original_item_name = item_from_webhook.get("Name", "æœªçŸ¥é¡¹ç›®")
    
    # å¦‚æœæ˜¯åˆ†é›†ï¼Œå°†åå­—æ ¼å¼åŒ–ä¸º "å‰§å - é›†å"ï¼Œæ–¹ä¾¿æ—¥å¿—æœç´¢
    raw_name = item_from_webhook.get("Name", "æœªçŸ¥é¡¹ç›®")
    series_name = item_from_webhook.get("SeriesName")
    
    if original_item_type == "Episode" and series_name:
        original_item_name = f"{series_name} - {raw_name}"
    else:
        original_item_name = raw_name
    
    trigger_types = ["Movie", "Series", "Season", "Episode", "BoxSet"]
    if not (original_item_id and original_item_type in trigger_types):
        logger.debug(f"  âœ Webhookäº‹ä»¶ '{event_type}' (é¡¹ç›®: {original_item_name}, ç±»å‹: {original_item_type}) è¢«å¿½ç•¥ã€‚")
        return jsonify({"status": "event_ignored_no_id_or_wrong_type"}), 200

    # ======================================================================
    # â˜…â˜…â˜… å¤„ç† collection.items.removed (æ£€æŸ¥æ˜¯å¦å˜ç©ºæ¶ˆå¤±) â˜…â˜…â˜…
    # ======================================================================
    if event_type == "collection.items.removed":
        # Emby å‘é€æ­¤äº‹ä»¶æ—¶ï¼ŒItem æŒ‡çš„æ˜¯åˆé›†æœ¬èº«
        collection_id = item_from_webhook.get("Id")
        collection_name = item_from_webhook.get("Name")

        if collection_id in DELETING_COLLECTIONS:
            logger.debug(f"  âœ Webhook: å¿½ç•¥åˆé›† '{collection_name}' çš„ç§»é™¤é€šçŸ¥ (æ­£åœ¨æ‰§è¡Œæ‰‹åŠ¨åˆ é™¤)ã€‚")
            return jsonify({"status": "ignored_manual_deletion"}), 200
        
        if collection_id:
            logger.info(f"  âœ Webhook: åˆé›† '{collection_name}' æœ‰æˆå‘˜ç§»é™¤ï¼Œæ­£åœ¨æ£€æŸ¥åˆé›†å­˜æ´»çŠ¶æ€...")
            
            def _check_collection_survival_task(processor=None):
                details = emby.get_emby_item_details(
                    item_id=collection_id,
                    emby_server_url=config_manager.APP_CONFIG.get("emby_server_url"),
                    emby_api_key=config_manager.APP_CONFIG.get("emby_api_key"),
                    user_id=config_manager.APP_CONFIG.get("emby_user_id"),
                    fields="Id",
                    silent_404=True
                )
                
                if not details:
                    logger.info(f"  ğŸ—‘ï¸ åˆé›† '{collection_name}' (ID: {collection_id}) å·²åœ¨ Emby ä¸­æ¶ˆå¤± (å¯èƒ½æ˜¯å˜ç©ºè‡ªåŠ¨åˆ é™¤)ï¼ŒåŒæ­¥åˆ é™¤æœ¬åœ°è®°å½•...")
                    tmdb_collection_db.delete_native_collection_by_emby_id(collection_id)
                else:
                    logger.debug(f"  âœ… åˆé›† '{collection_name}' ä¾ç„¶å­˜åœ¨ï¼Œæ— éœ€æ“ä½œã€‚")

            task_manager.submit_task(
                _check_collection_survival_task,
                task_name=f"æ£€æŸ¥åˆé›†å­˜æ´»: {collection_name}",
                processor_type='media'
            )
            return jsonify({"status": "collection_removal_check_started"}), 202

    if event_type == "library.deleted":
            if config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_MONITOR_ENABLED):
                logger.debug(f"  âœ Webhook: å¿½ç•¥ 'library.deleted' äº‹ä»¶ (å®æ—¶ç›‘æ§å·²å¯ç”¨ï¼Œç”±ç›‘æ§æ¨¡å—æ¥ç®¡æ¸…ç†)ã€‚")
                return jsonify({"status": "ignored_monitor_active"}), 200
            try:
                series_id_from_webhook = item_from_webhook.get("SeriesId") if original_item_type == "Episode" else None
                # ç›´æ¥è°ƒç”¨æ–°çš„ã€å¹²å‡€çš„æ•°æ®åº“å‡½æ•°
                maintenance_db.cleanup_deleted_media_item(
                    item_id=original_item_id,
                    item_name=original_item_name,
                    item_type=original_item_type,
                    series_id_from_webhook=series_id_from_webhook
                )
                # ==============================================================
                # â˜…â˜…â˜… åˆ é™¤åª’ä½“åï¼Œä¹Ÿä¸»åŠ¨åˆ·æ–°å‘é‡ç¼“å­˜ (ä¿æŒç¼“å­˜çº¯å‡€) â˜…â˜…â˜…
                # ==============================================================
                if config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_PROXY_ENABLED) and config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_AI_VECTOR):
                    # åªæœ‰åˆ é™¤äº† Movie æˆ– Series æ‰éœ€è¦åˆ·æ–°ï¼Œåˆ  Episode ä¸å½±å“å‘é‡åº“
                    if original_item_type in ['Movie', 'Series']:
                        try:
                            spawn(RecommendationEngine.refresh_cache)
                            logger.debug(f"  âœ [æ™ºèƒ½æ¨è] æ£€æµ‹åˆ°åª’ä½“åˆ é™¤ï¼Œå·²è§¦å‘å‘é‡ç¼“å­˜åˆ·æ–°ã€‚")
                        except Exception as e:
                            logger.warning(f"  âœ [æ™ºèƒ½æ¨è] è§¦å‘ç¼“å­˜åˆ·æ–°å¤±è´¥: {e}")
                # ==============================================================
                return jsonify({"status": "delete_event_processed"}), 200
            except Exception as e:
                logger.error(f"å¤„ç†åˆ é™¤äº‹ä»¶ for item {original_item_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                return jsonify({"status": "error_processing_remove_event", "error": str(e)}), 500
    # è¿‡æ»¤ä¸åœ¨å¤„ç†èŒƒå›´çš„åª’ä½“åº“
    if event_type in ["item.add", "library.new", "metadata.update", "image.update"]:
        processor = extensions.media_processor_instance
        
        # --- ã€æ‹¦æˆª 1ã€‘å¦‚æœæ˜¯ç³»ç»Ÿæ­£åœ¨ç”Ÿæˆçš„å°é¢ï¼Œç›´æ¥æ‹¦æˆªï¼Œä¸æŸ¥åº“ï¼Œä¸æŠ¥é”™ ---
        if event_type == "image.update" and original_item_id in UPDATING_IMAGES:
            logger.debug(f"  âœ Webhook: å¿½ç•¥é¡¹ç›® '{original_item_name}' çš„å›¾ç‰‡æ›´æ–°é€šçŸ¥ (ç³»ç»Ÿç”Ÿæˆçš„å°é¢)ã€‚")
            return jsonify({"status": "ignored_self_triggered_update"}), 200
        
        # --- ã€æ‹¦æˆª 2ã€‘å¦‚æœæ˜¯ç³»ç»Ÿæ­£åœ¨æ›´æ–°å…ƒæ•°æ®ï¼Œç›´æ¥æ‹¦æˆª ---
        if event_type == "metadata.update" and original_item_id in UPDATING_METADATA:
            logger.debug(f"  âœ Webhook: å¿½ç•¥é¡¹ç›® '{original_item_name}' çš„å…ƒæ•°æ®æ›´æ–°é€šçŸ¥ (ç³»ç»Ÿè§¦å‘çš„æ›´æ–°)ã€‚")
            return jsonify({"status": "ignored_self_triggered_metadata_update"}), 200

        # --- ã€æ‹¦æˆª 3ã€‘å¦‚æœæ˜¯åˆé›†(BoxSet)ï¼Œå®ƒæ²¡æœ‰ç‰©ç†è·¯å¾„ï¼Œç›´æ¥è·³è¿‡åº“è·¯å¾„æ£€æŸ¥ ---
        if original_item_type == "BoxSet":
            logger.trace(f"  âœ Webhook: é¡¹ç›® '{original_item_name}' æ˜¯åˆé›†ç±»å‹ï¼Œè·³è¿‡åª’ä½“åº“è·¯å¾„æ£€æŸ¥ã€‚")
            # æ³¨æ„ï¼šè¿™é‡Œä¸ returnï¼Œå› ä¸ºåé¢å¯èƒ½è¿˜æœ‰åˆé›†çš„å¤„ç†é€»è¾‘
            library_info = None 
        else:
            # æ­£å¸¸çš„åª’ä½“é¡¹ï¼Œæ‰å»è·å–æ‰€å±åº“ä¿¡æ¯
            library_info = emby.get_library_root_for_item(
                original_item_id, processor.emby_url, processor.emby_api_key, processor.emby_user_id
            )
        
        if library_info:
            lib_id = library_info.get("Id")
            lib_name = library_info.get("Name", "æœªçŸ¥åº“")
            allowed_libs = config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_EMBY_LIBRARIES_TO_PROCESS) or []

            # æ‰§è¡Œæ‰“æ ‡ï¼ˆå…¨åº“ç”Ÿæ•ˆï¼‰
            if event_type in ["item.add", "library.new"]:
                spawn(_handle_immediate_tagging_with_lib, original_item_id, original_item_name, lib_id, lib_name)

            # ã€å…³é”®æ‹¦æˆªç‚¹ã€‘
            if lib_id not in allowed_libs:
                logger.trace(f"  âœ Webhook: é¡¹ç›® '{original_item_name}' æ‰€å±åº“ '{lib_name}' (ID: {lib_id}) ä¸åœ¨å¤„ç†èŒƒå›´å†…ï¼Œå·²è·³è¿‡ã€‚")
                return jsonify({"status": "ignored_library"}), 200

    if event_type in ["item.add", "library.new"]:
        spawn(_wait_for_stream_data_and_enqueue, original_item_id, original_item_name, original_item_type)
        
        logger.info(f"  âœ Webhook: æ”¶åˆ°å…¥åº“äº‹ä»¶ '{original_item_name}'ï¼Œå·²åˆ†æ´¾é¢„æ£€ä»»åŠ¡ã€‚")
        return jsonify({"status": "processing_started_with_stream_check", "item_id": original_item_id}), 202

    # --- ä¸º metadata.update å’Œ image.update äº‹ä»¶å‡†å¤‡é€šç”¨å˜é‡ ---
    id_to_process = original_item_id
    name_for_task = original_item_name
    
    if original_item_type == "Episode":
        series_id = emby.get_series_id_from_child_id(
            original_item_id, extensions.media_processor_instance.emby_url,
            extensions.media_processor_instance.emby_api_key, extensions.media_processor_instance.emby_user_id, item_name=original_item_name
        )
        if not series_id:
            logger.warning(f"  âœ Webhook '{event_type}': å‰§é›† '{original_item_name}' æœªæ‰¾åˆ°æ‰€å±å‰§é›†ï¼Œè·³è¿‡ã€‚")
            return jsonify({"status": "event_ignored_episode_no_series_id"}), 200
        id_to_process = series_id
        
        full_series_details = emby.get_emby_item_details(
            item_id=id_to_process, emby_server_url=extensions.media_processor_instance.emby_url,
            emby_api_key=extensions.media_processor_instance.emby_api_key, user_id=extensions.media_processor_instance.emby_user_id
        )
        if full_series_details:
            name_for_task = full_series_details.get("Name", f"æœªçŸ¥å‰§é›†(ID:{id_to_process})")

    # --- åˆ†ç¦» metadata.update å’Œ image.update çš„å¤„ç†é€»è¾‘ ---
    if event_type == "metadata.update":
        with UPDATE_DEBOUNCE_LOCK:
            if id_to_process in UPDATE_DEBOUNCE_TIMERS:
                old_timer = UPDATE_DEBOUNCE_TIMERS[id_to_process]
                old_timer.kill()
                logger.debug(f"  âœ å·²ä¸º '{name_for_task}' å–æ¶ˆäº†æ—§çš„åŒæ­¥è®¡æ—¶å™¨ï¼Œå°†ä»¥æœ€æ–°çš„å…ƒæ•°æ®æ›´æ–°äº‹ä»¶ä¸ºå‡†ã€‚")

            logger.info(f"  âœ ä¸º '{name_for_task}' è®¾ç½®äº† {UPDATE_DEBOUNCE_TIME} ç§’çš„å…ƒæ•°æ®åŒæ­¥å»¶è¿Ÿï¼Œä»¥åˆå¹¶è¿ç»­çš„æ›´æ–°äº‹ä»¶ã€‚")
            new_timer = spawn_later(
                UPDATE_DEBOUNCE_TIME,
                _trigger_metadata_update_task,
                item_id=id_to_process,
                item_name=name_for_task
            )
            UPDATE_DEBOUNCE_TIMERS[id_to_process] = new_timer
        return jsonify({"status": "metadata_update_task_debounced", "item_id": id_to_process}), 202

    elif event_type == "image.update":
        
        # 1. å…ˆè·å–åŸå§‹çš„æè¿°
        original_update_description = data.get("Description", "Webhook Image Update")
        webhook_received_at_iso = datetime.now(timezone.utc).isoformat()

        # 2. å‡†å¤‡ä¸€ä¸ªå˜é‡æ¥å­˜æ”¾æœ€ç»ˆè¦æ‰§è¡Œçš„æè¿°
        final_update_description = original_update_description

        with UPDATE_DEBOUNCE_LOCK:
            # 3. æ£€æŸ¥æ˜¯å¦å·²æœ‰è®¡æ—¶å™¨
            if id_to_process in UPDATE_DEBOUNCE_TIMERS:
                old_timer = UPDATE_DEBOUNCE_TIMERS[id_to_process]
                old_timer.kill()
                logger.debug(f"  âœ å·²ä¸º '{name_for_task}' å–æ¶ˆäº†æ—§çš„åŒæ­¥è®¡æ—¶å™¨ï¼Œå°†ä»¥æœ€æ–°çš„å°é¢æ›´æ–°äº‹ä»¶ä¸ºå‡†ã€‚")
                
                # â˜…â˜…â˜… å…³é”®é€»è¾‘ï¼šå¦‚æœå–æ¶ˆäº†æ—§çš„ï¼Œè¯´æ˜å‘ç”Ÿäº†åˆå¹¶ï¼Œæˆ‘ä»¬ä¸å†ç›¸ä¿¡å•ä¸€æè¿° â˜…â˜…â˜…
                logger.info(f"  âœ æ£€æµ‹åˆ°å›¾ç‰‡æ›´æ–°äº‹ä»¶åˆå¹¶ï¼Œå°†ä»»åŠ¡å‡çº§ä¸ºâ€œå®Œå…¨åŒæ­¥â€ã€‚")
                final_update_description = "Multiple image updates detected" # ç»™ä¸€ä¸ªé€šç”¨æè¿°

            logger.info(f"  âœ ä¸º '{name_for_task}' è®¾ç½®äº† {UPDATE_DEBOUNCE_TIME} ç§’çš„å°é¢å¤‡ä»½å»¶è¿Ÿ...")
            new_timer = spawn_later(
                UPDATE_DEBOUNCE_TIME,
                _trigger_images_update_task,
                item_id=id_to_process,
                item_name=name_for_task,
                update_description=final_update_description, # <-- ä½¿ç”¨æˆ‘ä»¬æœ€ç»ˆå†³å®šçš„æè¿°
                sync_timestamp_iso=webhook_received_at_iso
            )
            UPDATE_DEBOUNCE_TIMERS[id_to_process] = new_timer
        
        return jsonify({"status": "asset_update_task_debounced", "item_id": id_to_process}), 202

    return jsonify({"status": "event_unhandled"}), 500