# web_app.py
from gevent import monkey
monkey.patch_all()
import os
import sys
import shutil
from jinja2 import Environment, FileSystemLoader
from handler.actor_sync import UnifiedSyncHandler
import extensions
from flask import Flask, render_template, request, redirect, url_for, jsonify, flash, stream_with_context, send_from_directory,Response, abort, session
from werkzeug.utils import safe_join, secure_filename
from watchlist_processor import WatchlistProcessor
from datetime import datetime
from handler.emby import get_emby_server_info 
import task_manager
from tasks.core import get_task_registry 
from typing import Dict, Any
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import atexit # ç”¨äºåº”ç”¨é€€å‡ºå¤„ç†
from ai_translator import AITranslator
from core_processor import MediaProcessor
from actor_subscription_processor import ActorSubscriptionProcessor
from werkzeug.security import generate_password_hash, check_password_hash
from actor_utils import enrich_all_actor_aliases_task
from handler.custom_collection import RecommendationEngine
from flask import session
from croniter import croniter
from scheduler_manager import scheduler_manager
from reverse_proxy import proxy_app
import logging
from gevent import spawn_later # Added for debouncing
# --- å¯¼å…¥è“å›¾ ---
from routes.watchlist import watchlist_bp
from routes.tmdb_collections import collections_bp
from routes.custom_collections import custom_collections_bp
from routes.actor_subscriptions import actor_subscriptions_bp
from routes.logs import logs_bp
from routes.database_admin import db_admin_bp
from routes.system import system_bp
from routes.media import media_api_bp, media_proxy_bp
from routes.actions import actions_bp
from routes.cover_generator_config import cover_generator_config_bp
from routes.tasks import tasks_bp
from routes.resubscribe import resubscribe_bp
from routes.media_cleanup import media_cleanup_bp
from routes.user_management import user_management_bp
from routes.webhook import webhook_bp
from routes.unified_auth import unified_auth_bp
from routes.user_portal import user_portal_bp
from routes.discover import discover_bp
from routes.nullbr import nullbr_bp
from routes.p115 import p115_bp
# --- æ ¸å¿ƒæ¨¡å—å¯¼å…¥ ---
import constants # ä½ çš„å¸¸é‡å®šä¹‰\
import logging
from logger_setup import frontend_log_queue, add_file_handler # æ—¥å¿—è®°å½•å™¨å’Œå‰ç«¯æ—¥å¿—é˜Ÿåˆ—
import config_manager
from database import connection, settings_db

import task_manager
# â˜…â˜…â˜… æ–°å¢ï¼šå¯¼å…¥ç›‘æ§æœåŠ¡ â˜…â˜…â˜…
from monitor_service import MonitorService 
# å¯¼å…¥ DoubanApi
try:
    from handler.douban import DoubanApi
    DOUBAN_API_AVAILABLE = True
except ImportError:
    DOUBAN_API_AVAILABLE = False
    class DoubanApi:
        def __init__(self, *args, **kwargs): pass
        def close(self): pass
# --- æ ¸å¿ƒæ¨¡å—å¯¼å…¥ç»“æŸ ---
logger = logging.getLogger(__name__)
logging.getLogger("apscheduler.scheduler").setLevel(logging.WARNING)
logging.getLogger('werkzeug').setLevel(logging.ERROR)
app = Flask(__name__, static_folder='static')
# --- ä¼˜åŒ– Session å¯†é’¥æŒä¹…åŒ– ---
secret_file_path = os.path.join(config_manager.PERSISTENT_DATA_PATH, '.flask_secret')
if os.path.exists(secret_file_path):
    with open(secret_file_path, 'rb') as f:
        app.secret_key = f.read()
else:
    secret_key = os.urandom(24)
    app.secret_key = secret_key
    try:
        with open(secret_file_path, 'wb') as f:
            f.write(secret_key)
    except Exception as e:
        logger.warning(f"æ— æ³•ä¿å­˜ Session å¯†é’¥ï¼Œé‡å¯åç”¨æˆ·éœ€é‡æ–°ç™»å½•: {e}")

#è¿‡æ»¤åº•å±‚æ—¥å¿—
logging.getLogger("requests").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("docker").setLevel(logging.WARNING)
logging.getLogger("PIL").setLevel(logging.WARNING)
logging.getLogger("geventwebsocket").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("watchdog").setLevel(logging.WARNING)
# --- å…¨å±€å˜é‡ ---

JOB_ID_FULL_SCAN = "scheduled_full_scan"
JOB_ID_SYNC_PERSON_MAP = "scheduled_sync_person_map"
JOB_ID_PROCESS_WATCHLIST = "scheduled_process_watchlist"
JOB_ID_REVIVAL_CHECK = "scheduled_revival_check"

# â˜…â˜…â˜… æ–°å¢ï¼šå…¨å±€ç›‘æ§æœåŠ¡å®ä¾‹ â˜…â˜…â˜…
monitor_service_instance = None

# --- ä¿å­˜é…ç½®å¹¶é‡æ–°åŠ è½½çš„å‡½æ•° ---
def save_config_and_reload(new_config: Dict[str, Any]):
    """
    ã€æ–°ç‰ˆã€‘è°ƒç”¨é…ç½®ç®¡ç†å™¨ä¿å­˜é…ç½®ï¼Œå¹¶åœ¨æ­¤å¤„æ‰§è¡Œæ‰€æœ‰å¿…è¦çš„é‡æ–°åˆå§‹åŒ–æ“ä½œã€‚
    """
    global monitor_service_instance
    try:
        # æ­¥éª¤ 1: è°ƒç”¨ config_manager æ¥ä¿å­˜æ–‡ä»¶å’Œæ›´æ–°å†…å­˜ä¸­çš„ config_manager.APP_CONFIG
        config_manager.save_config(new_config)
        
        # æ­¥éª¤ 2: æ‰§è¡Œæ‰€æœ‰ä¾èµ–äºæ–°é…ç½®çš„é‡æ–°åˆå§‹åŒ–é€»è¾‘
        initialize_processors()
        
        scheduler_manager.update_all_scheduled_jobs()
        
        # â˜…â˜…â˜… æ–°å¢ï¼šé‡å¯ç›‘æ§æœåŠ¡ä»¥åº”ç”¨æ–°é…ç½® â˜…â˜…â˜…
        if monitor_service_instance:
            monitor_service_instance.stop()
        
        if extensions.media_processor_instance:
            monitor_service_instance = MonitorService(config_manager.APP_CONFIG, extensions.media_processor_instance)
            monitor_service_instance.start()
        
        logger.info("  âœ… æ–°é…ç½®é‡æ–°åˆå§‹åŒ–å®Œæ¯•ã€‚")
        
    except Exception as e:
        logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶æˆ–é‡æ–°åˆå§‹åŒ–æ—¶å¤±è´¥: {e}", exc_info=True)
        # å‘ä¸ŠæŠ›å‡ºå¼‚å¸¸ï¼Œè®© API ç«¯ç‚¹å¯ä»¥æ•è·å®ƒå¹¶è¿”å›é”™è¯¯ä¿¡æ¯
        raise

# --- åˆå§‹åŒ–æ‰€æœ‰éœ€è¦çš„å¤„ç†å™¨å®ä¾‹ ---
def initialize_processors():
    """åˆå§‹åŒ–æ‰€æœ‰å¤„ç†å™¨ï¼Œå¹¶å°†å®ä¾‹èµ‹å€¼ç»™ extensions æ¨¡å—ä¸­çš„å…¨å±€å˜é‡ã€‚"""
    if not config_manager.APP_CONFIG:
        logger.error("æ— æ³•åˆå§‹åŒ–å¤„ç†å™¨ï¼šå…¨å±€é…ç½® APP_CONFIG ä¸ºç©ºã€‚")
        return

    current_config = config_manager.APP_CONFIG.copy()

    # --- 1. åˆ›å»ºå®ä¾‹å¹¶å­˜å‚¨åœ¨å±€éƒ¨å˜é‡ä¸­ ---

    # --- åˆå§‹åŒ–å…±äº«çš„ AI å®ä¾‹ ---
    shared_ai_translator = None
    
    # æ£€æŸ¥æ˜¯å¦å¼€å¯äº†ä»»æ„ AI åŠŸèƒ½
    ai_enabled = any([
        current_config.get(constants.CONFIG_OPTION_AI_TRANSLATE_ACTOR_ROLE, False),
        current_config.get(constants.CONFIG_OPTION_AI_TRANSLATE_TITLE, False),    
        current_config.get(constants.CONFIG_OPTION_AI_TRANSLATE_OVERVIEW, False), 
        current_config.get(constants.CONFIG_OPTION_AI_TRANSLATE_EPISODE_OVERVIEW, False),
        current_config.get(constants.CONFIG_OPTION_AI_VECTOR, False),
    ])

    if ai_enabled:
        try:
            shared_ai_translator = AITranslator(current_config)
            logger.debug("  âœ… AIå¢å¼ºæœåŠ¡å®ä¾‹å·²åˆå§‹åŒ–ã€‚")
        except Exception as e:
            logger.error(f"  âŒ AITranslator åˆå§‹åŒ–å¤±è´¥: {e}")

    # --- åˆå§‹åŒ–å…±äº«çš„ Douban å®ä¾‹ ---
    shared_douban_api = None
    if getattr(constants, 'DOUBAN_API_AVAILABLE', False):
        try:
            # ä»é…ç½®ä¸­è·å–å‚æ•°
            douban_cooldown = current_config.get(constants.CONFIG_OPTION_DOUBAN_DEFAULT_COOLDOWN, 2.0)
            douban_cookie = current_config.get(constants.CONFIG_OPTION_DOUBAN_COOKIE, "")
            
            if not douban_cookie:
                logger.debug(f"é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ° '{constants.CONFIG_OPTION_DOUBAN_COOKIE}'ã€‚è±†ç“£åŠŸèƒ½å¯èƒ½å—é™ã€‚")
            
            shared_douban_api = DoubanApi(
                cooldown_seconds=douban_cooldown,
                user_cookie=douban_cookie
            )
            logger.debug("  âœ… DoubanApi å…±äº«å®ä¾‹å·²åˆå§‹åŒ–ã€‚")
        except Exception as e:
            logger.error(f"DoubanApi åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
    
    # åˆå§‹åŒ– server_id_local
    server_id_local = None
    emby_url = current_config.get("emby_server_url")
    emby_key = current_config.get("emby_api_key")
    
    if emby_url and emby_key:
        # --- ä¼˜åŒ–å¯åŠ¨é€»è¾‘ï¼šä¼˜å…ˆæ£€æŸ¥ç¼“å­˜ï¼Œå†³å®šè¶…æ—¶ç­–ç•¥ ---
        cached_id = settings_db.get_setting("emby_server_id_cache")
        
        # å¦‚æœæœ‰ç¼“å­˜ï¼Œæˆ‘ä»¬åªç»™ 5 ç§’é’Ÿå°è¯•è¿æ¥ Emby (å¿«é€Ÿå¤±è´¥ç­–ç•¥)
        # å¦‚æœæ²¡ç¼“å­˜ï¼Œæˆ‘ä»¬ç»™ 20 ç§’ (å¿…é¡»è·å–ç­–ç•¥)
        startup_timeout = 5 if cached_id else 20
        
        logger.info(f"  âœ æ­£åœ¨å°è¯•è¿æ¥ Emby è·å– Server ID (è¶…æ—¶è®¾å®š: {startup_timeout}s)...")
        
        # å°è¯•è·å–åœ¨çº¿ä¿¡æ¯
        server_info = get_emby_server_info(emby_url, emby_key, timeout=startup_timeout)
        
        if server_info and server_info.get("Id"):
            server_id_local = server_info.get("Id")
            logger.trace(f"æˆåŠŸè·å–åˆ° Emby Server ID: {server_id_local}")
            # --- ç¼“å­˜ Server ID ---
            try:
                settings_db.save_setting("emby_server_id_cache", server_id_local)
            except Exception as e:
                logger.warning(f"ç¼“å­˜ Emby Server ID å¤±è´¥: {e}")
        else:
            # --- ç½‘ç»œè·å–å¤±è´¥ï¼Œå›é€€åˆ°ç¼“å­˜ ---
            if cached_id:
                server_id_local = cached_id
                logger.warning(f"âš ï¸ æ— æ³•è¿æ¥ Emby æœåŠ¡å™¨ (æˆ–è¶…æ—¶)ï¼Œå·²ä½¿ç”¨ç¼“å­˜çš„ Server ID: {server_id_local} ç»§ç»­å¯åŠ¨ã€‚")
            else:
                logger.error("âŒ æ— æ³•è¿æ¥ Emby ä¸”æœ¬åœ°æ— ç¼“å­˜ Server IDï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™ã€‚")

    # åˆå§‹åŒ– media_processor_instance_local
    try:
        media_processor_instance_local = MediaProcessor(
            config=current_config, 
            ai_translator=shared_ai_translator,
            douban_api=shared_douban_api 
        )
        logger.trace("  ->æ ¸å¿ƒå¤„ç†å™¨ å®ä¾‹å·²åˆ›å»º/æ›´æ–°ã€‚")
    except Exception as e:
        logger.error(f"åˆ›å»º MediaProcessor å®ä¾‹å¤±è´¥: {e}", exc_info=True)
        media_processor_instance_local = None

    # åˆå§‹åŒ– watchlist_processor_instance_local
    try:
        watchlist_processor_instance_local = WatchlistProcessor(
            config=current_config, 
            ai_translator=shared_ai_translator,
            douban_api=shared_douban_api
        )
        logger.trace("WatchlistProcessor å®ä¾‹å·²æˆåŠŸåˆå§‹åŒ–ã€‚")
    except Exception as e:
        logger.error(f"åˆ›å»º WatchlistProcessor å®ä¾‹å¤±è´¥: {e}", exc_info=True)
        watchlist_processor_instance_local = None

    # åˆå§‹åŒ– actor_subscription_processor_instance_local
    try:
        actor_subscription_processor_instance_local = ActorSubscriptionProcessor(config=current_config)
        logger.trace("ActorSubscriptionProcessor å®ä¾‹å·²æˆåŠŸåˆå§‹åŒ–ã€‚")
    except Exception as e:
        logger.error(f"åˆ›å»º ActorSubscriptionProcessor å®ä¾‹å¤±è´¥: {e}", exc_info=True)
        actor_subscription_processor_instance_local = None


    # --- âœ¨âœ¨âœ¨ ç®€åŒ–ä¸ºâ€œå•ä¸€èµ‹å€¼â€ âœ¨âœ¨âœ¨ ---
    # ç›´æ¥èµ‹å€¼ç»™ extensions æ¨¡å—çš„å…¨å±€å˜é‡
    extensions.media_processor_instance = media_processor_instance_local
    extensions.watchlist_processor_instance = watchlist_processor_instance_local
    extensions.actor_subscription_processor_instance = actor_subscription_processor_instance_local
    extensions.EMBY_SERVER_ID = server_id_local

# --- ç”ŸæˆNginxé…ç½® ---
def ensure_nginx_config():
    """
    ã€Jinja2 å®¹å™¨é›†æˆç‰ˆã€‘ä½¿ç”¨ Jinja2 æ¨¡æ¿å¼•æ“ï¼Œç”Ÿæˆä¾›å®¹å™¨å†… Nginx ä½¿ç”¨çš„é…ç½®æ–‡ä»¶ã€‚
    """
    final_config_path = '/etc/nginx/conf.d/default.conf'
    # æ£€æŸ¥å¼€å…³
    if not config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_PROXY_ENABLED):
        logger.info("åå‘ä»£ç†åŠŸèƒ½æœªå¯ç”¨ï¼Œæ­£åœ¨æ¸…ç† Nginx é»˜è®¤é…ç½®ä»¥é‡Šæ”¾ç«¯å£...")
        try:
            # å†™å…¥ç©ºæ–‡ä»¶ï¼Œç›¸å½“äºç¦ç”¨äº† Nginx çš„é»˜è®¤ç«™ç‚¹
            with open(final_config_path, 'w') as f:
                f.write("# Proxy disabled in config.ini") 
            return
        except Exception as e:
            logger.warning(f"æ¸…ç† Nginx é»˜è®¤é…ç½®å¤±è´¥: {e}")
            return
    logger.info("æ­£åœ¨ç”Ÿæˆ Nginx é…ç½®æ–‡ä»¶...")
    
    template_dir = os.path.join(os.getcwd(), 'templates', 'nginx')
    template_filename = 'emby_proxy.conf.template'

    try:
        # 1. è®¾ç½® Jinja2 ç¯å¢ƒ
        env = Environment(loader=FileSystemLoader(template_dir))
        template = env.get_template(template_filename)

        # 2. ä» APP_CONFIG è·å–å€¼
        emby_url = config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_EMBY_SERVER_URL, "")
        nginx_listen_port = config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_PROXY_PORT, 8097)

        # 3. å‡†å¤‡æ›¿æ¢å€¼
        emby_upstream = emby_url.replace("http://", "").replace("https://", "").rstrip('/')
        # â˜…â˜…â˜… æ ¸å¿ƒä¿®æ”¹ 2: Nginx å’Œ Python ä»£ç†åœ¨åŒä¸€å®¹å™¨å†…ï¼Œä½¿ç”¨ localhost é€šä¿¡ â˜…â˜…â˜…
        proxy_upstream = "127.0.0.1:7758" 

        if not emby_upstream:
            logger.error("config.ini ä¸­æœªé…ç½® Emby æœåŠ¡å™¨åœ°å€ï¼Œæ— æ³•ç”Ÿæˆ Nginx é…ç½®ï¼")
            sys.exit(1) # ä¸¥é‡é”™è¯¯ï¼Œç›´æ¥é€€å‡º

        # 4. å¡«å……æ¨¡æ¿
        context = {
            'EMBY_UPSTREAM': emby_upstream,
            'PROXY_UPSTREAM': proxy_upstream,
            'NGINX_LISTEN_PORT': nginx_listen_port,
            'NGINX_MAX_BODY_SIZE': '128m'
        }
        final_config_content = template.render(context)

        # 5. å†™å…¥æœ€ç»ˆçš„é…ç½®æ–‡ä»¶
        with open(final_config_path, 'w', encoding='utf-8') as f:
            f.write(final_config_content)
        
        logger.info(f"âœ… Nginx é…ç½®æ–‡ä»¶å·²æˆåŠŸç”Ÿæˆäº: {final_config_path}")

    except Exception as e:
        logger.error(f"ç”Ÿæˆ Nginx é…ç½®æ–‡ä»¶æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        sys.exit(1) # ä¸¥é‡é”™è¯¯ï¼Œç›´æ¥é€€å‡º

# --- æ£€æŸ¥å­—ä½“æ–‡ä»¶ ---
def ensure_cover_generator_fonts():
    """
    å¯åŠ¨æ—¶æ£€æŸ¥ cover_generator/fonts ç›®å½•ä¸‹æ˜¯å¦æœ‰æŒ‡å®šå­—ä½“æ–‡ä»¶ï¼Œ
    è‹¥ç¼ºå°‘åˆ™ä»é¡¹ç›®æ ¹ç›®å½•çš„ fonts ç›®å½•æ‹·è´è¿‡å»ã€‚
    """
    cover_fonts_dir = os.path.join(config_manager.PERSISTENT_DATA_PATH, 'cover_generator', 'fonts')
    project_fonts_dir = os.path.join(os.getcwd(), 'fonts')  # é¡¹ç›®æ ¹ç›®å½•fonts

    required_fonts = [
        "en_font.ttf",
        "en_font_multi_1.otf",
        "zh_font.ttf",
        "zh_font_multi_1.ttf",
    ]

    if not os.path.exists(cover_fonts_dir):
        os.makedirs(cover_fonts_dir, exist_ok=True)
        logger.trace(f"å·²åˆ›å»ºå­—ä½“ç›®å½•ï¼š{cover_fonts_dir}")

    for font_name in required_fonts:
        dest_path = os.path.join(cover_fonts_dir, font_name)
        if not os.path.isfile(dest_path):
            src_path = os.path.join(project_fonts_dir, font_name)
            if os.path.isfile(src_path):
                try:
                    shutil.copy2(src_path, dest_path)
                    logger.trace(f"å·²æ‹·è´ç¼ºå¤±å­—ä½“æ–‡ä»¶ {font_name} åˆ° {cover_fonts_dir}")
                except Exception as e:
                    logger.error(f"æ‹·è´å­—ä½“æ–‡ä»¶ {font_name} å¤±è´¥: {e}", exc_info=True)
            else:
                logger.warning(f"é¡¹ç›®æ ¹ç›®å½•ç¼ºå°‘å­—ä½“æ–‡ä»¶ {font_name}ï¼Œæ— æ³•æ‹·è´è‡³ {cover_fonts_dir}")

# --- åº”ç”¨é€€å‡ºå¤„ç† ---
def application_exit_handler():
    # global media_processor_instance, scheduler, task_worker_thread # ä¸å†éœ€è¦ scheduler
    global media_processor_instance, task_worker_thread, monitor_service_instance # ä¿®æ­£åçš„
    logger.info("åº”ç”¨ç¨‹åºæ­£åœ¨é€€å‡º (atexit)ï¼Œæ‰§è¡Œæ¸…ç†æ“ä½œ...")

    # 1. ç«‹åˆ»é€šçŸ¥å½“å‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡åœæ­¢
    if extensions.media_processor_instance: # ä» extensions è·å–
        logger.info("æ­£åœ¨å‘é€åœæ­¢ä¿¡å·ç»™å½“å‰ä»»åŠ¡...")
        extensions.media_processor_instance.signal_stop()

    task_manager.clear_task_queue()
    task_manager.stop_task_worker()

    # â˜…â˜…â˜… æ–°å¢ï¼šåœæ­¢ç›‘æ§æœåŠ¡ â˜…â˜…â˜…
    if monitor_service_instance:
        monitor_service_instance.stop()

    # 4. å…³é—­å…¶ä»–èµ„æº
    if extensions.media_processor_instance: # ä» extensions è·å–
        extensions.media_processor_instance.close()
    
    scheduler_manager.shutdown()
    
    logger.info("atexit æ¸…ç†æ“ä½œæ‰§è¡Œå®Œæ¯•ã€‚")
atexit.register(application_exit_handler)

# --- åä»£ç›‘æ§ ---
@app.route('/api/health')
def health_check():
    """ä¸€ä¸ªç®€å•çš„å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼Œç”¨äº Docker healthcheckã€‚"""
    return jsonify({"status": "ok"}), 200

# --- å…œåº•è·¯ç”±ï¼Œå¿…é¡»æ”¾æœ€å ---
@app.route('/', defaults={'path': ''})
@app.route('/<path:path>')
def serve(path):
    static_folder_path = app.static_folder 

    if path != "" and os.path.exists(os.path.join(static_folder_path, path)):
        return send_from_directory(static_folder_path, path)
    else:
        return send_from_directory(static_folder_path, 'index.html')
    
# +++ åœ¨åº”ç”¨å¯¹è±¡ä¸Šæ³¨å†Œæ‰€æœ‰è“å›¾ +++
app.register_blueprint(watchlist_bp)
app.register_blueprint(collections_bp)
app.register_blueprint(custom_collections_bp)
app.register_blueprint(actor_subscriptions_bp)
app.register_blueprint(logs_bp)
app.register_blueprint(db_admin_bp)
app.register_blueprint(system_bp)
app.register_blueprint(media_api_bp) 
app.register_blueprint(media_proxy_bp)
app.register_blueprint(actions_bp)
app.register_blueprint(cover_generator_config_bp)
app.register_blueprint(tasks_bp)
app.register_blueprint(resubscribe_bp)
app.register_blueprint(media_cleanup_bp)
app.register_blueprint(user_management_bp)
app.register_blueprint(webhook_bp)
app.register_blueprint(unified_auth_bp)
app.register_blueprint(user_portal_bp)
app.register_blueprint(discover_bp)
app.register_blueprint(nullbr_bp)
app.register_blueprint(p115_bp)

def main_app_start():
    """å°†ä¸»åº”ç”¨å¯åŠ¨é€»è¾‘å°è£…æˆä¸€ä¸ªå‡½æ•°"""
    global monitor_service_instance # å£°æ˜ä½¿ç”¨å…¨å±€å˜é‡
    from gevent.pywsgi import WSGIServer
    from geventwebsocket.handler import WebSocketHandler
    import gevent

    logger.info(f"  âœ åº”ç”¨ç¨‹åºå¯åŠ¨... ç‰ˆæœ¬: {constants.APP_VERSION}")
    
    config_manager.load_config()
    
    config_manager.LOG_DIRECTORY = os.path.join(config_manager.PERSISTENT_DATA_PATH, 'logs')
    try:
        log_size = int(config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_LOG_ROTATION_SIZE_MB, constants.DEFAULT_LOG_ROTATION_SIZE_MB))
        log_backups = int(config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_LOG_ROTATION_BACKUPS, constants.DEFAULT_LOG_ROTATION_BACKUPS))
    except (ValueError, TypeError):
        log_size = constants.DEFAULT_LOG_ROTATION_SIZE_MB
        log_backups = constants.DEFAULT_LOG_ROTATION_BACKUPS
    add_file_handler(log_directory=config_manager.LOG_DIRECTORY, log_size_mb=log_size, log_backups=log_backups)
    
    connection.init_db()

    ensure_cover_generator_fonts()
    initialize_processors()
    task_manager.start_task_worker_if_not_running()
    scheduler_manager.start()

    # â˜…â˜…â˜… æ–°å¢ï¼šå¯åŠ¨å®æ—¶ç›‘æ§æœåŠ¡ â˜…â˜…â˜…
    try:
        if extensions.media_processor_instance:
            monitor_service_instance = MonitorService(config_manager.APP_CONFIG, extensions.media_processor_instance)
            monitor_service_instance.start()
    except Exception as e:
        logger.error(f"å¯åŠ¨å®æ—¶ç›‘æ§æœåŠ¡å¤±è´¥: {e}", exc_info=True)

    def warmup_vector_cache():
        try:
            logger.debug("  ğŸ”¥ æ­£åœ¨åå°é¢„åŠ è½½å‘é‡æ•°æ®...")
            # åªéœ€è¦å®ä¾‹åŒ–ä¸€ä¸ªå¼•æ“å¹¶è°ƒç”¨ _get_vector_data å³å¯è§¦å‘åŠ è½½
            # æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦ api_keyï¼Œå› ä¸ºåªè¯»åº“
            engine = RecommendationEngine(tmdb_api_key="dummy")
            engine._get_vector_data()
            logger.debug("  âœ… å‘é‡æ•°æ®é¢„åŠ è½½å®Œæˆã€‚")
        except Exception as e:
            logger.warning(f"  âš ï¸ å‘é‡é¢„åŠ è½½å¤±è´¥ (ä¸å½±å“å¯åŠ¨): {e}")

    if config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_PROXY_ENABLED):
        # è¿™è¡Œä»£ç ä¼šå¯åŠ¨ä¸€ä¸ªåå°æ­»å¾ªç¯ï¼Œæ¯éš” 30 åˆ†é’Ÿåˆ·æ–°ä¸€æ¬¡æ•°æ®
        # ä¸”ç¬¬ä¸€æ¬¡ä¼šç«‹å³æ‰§è¡Œï¼Œèµ·åˆ°â€œé¢„çƒ­â€çš„ä½œç”¨
        RecommendationEngine.start_auto_refresh_loop()
    else:
        logger.debug("  âŒ è™šæ‹Ÿåº“åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡å‘é‡é¢„åŠ è½½ä»¥èŠ‚çœå†…å­˜ã€‚")
    
    def run_proxy_server():
        if config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_PROXY_ENABLED):
            try:
                internal_proxy_port = 7758
                external_port = config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_PROXY_PORT, 8097)
                logger.info(f"  ğŸš€ [è™šæ‹Ÿåº“] æœåŠ¡å™¨å·²å¯åŠ¨ (å®¹å™¨ç›‘å¬ç«¯å£: {external_port})")
                proxy_server = WSGIServer(('0.0.0.0', internal_proxy_port), proxy_app, handler_class=WebSocketHandler)
                proxy_server.serve_forever()
            except Exception as e:
                logger.error(f"å¯åŠ¨è™šæ‹Ÿåº“æœåŠ¡å¤±è´¥: {e}", exc_info=True)
        else:
            logger.info("è™šæ‹Ÿåº“æœªåœ¨é…ç½®ä¸­å¯ç”¨ã€‚")

    gevent.spawn(run_proxy_server)

    main_app_port = int(constants.WEB_APP_PORT)
    logger.info(f"  âœ… [ä¸»åº”ç”¨] æœåŠ¡å™¨å·²å¯åŠ¨ (å®¹å™¨ç›‘å¬ç«¯å£: {main_app_port})")
    
    class NullLogger:
        def write(self, data): pass
        def flush(self): pass

    main_server = WSGIServer(('0.0.0.0', main_app_port), app, log=NullLogger())
    main_server.serve_forever()

# â˜…â˜…â˜… æ ¸å¿ƒä¿®æ”¹ 2: æ–°å¢çš„å¯åŠ¨é€»è¾‘ï¼Œç”¨äºå¤„ç†å‘½ä»¤è¡Œå‚æ•° â˜…â˜…â˜…
if __name__ == '__main__':
    # æ£€æŸ¥æ˜¯å¦ä» entrypoint.sh ä¼ å…¥äº† 'generate-nginx-config' å‚æ•°
    if len(sys.argv) > 1 and sys.argv[1] == 'generate-nginx-config':
        print("Initializing to generate Nginx config...")
        # åªéœ€è¦åŠ è½½é…ç½®å’Œæ—¥å¿—ï¼Œç„¶åç”Ÿæˆå³å¯
        config_manager.load_config()
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨ï¼Œé¿å…æŠ¥é”™
        log_dir = os.path.join(config_manager.PERSISTENT_DATA_PATH, 'logs')
        os.makedirs(log_dir, exist_ok=True)
        add_file_handler(log_directory=log_dir)
        
        ensure_nginx_config()
        print("Nginx config generated successfully.")
        sys.exit(0) # æ‰§è¡Œå®Œæ¯•åæ­£å¸¸é€€å‡º
    else:
        # å¦‚æœæ²¡æœ‰ç‰¹æ®Šå‚æ•°ï¼Œåˆ™æ­£å¸¸å¯åŠ¨æ•´ä¸ªåº”ç”¨
        main_app_start()

# # --- ä¸»ç¨‹åºå…¥å£ç»“æŸ ---