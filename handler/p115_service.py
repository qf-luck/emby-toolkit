# handler/p115_service.py
import logging
import requests
import random
import os
import re
import threading
import time
import config_manager
import constants
from database import settings_db
import handler.tmdb as tmdb
import utils
try:
    from p115client import P115Client
except ImportError:
    P115Client = None

logger = logging.getLogger(__name__)

# --- CMSé€šçŸ¥é˜²æŠ–å®šæ—¶å™¨ ---
_cms_timer = None
_cms_lock = threading.Lock()

def get_config():
    return settings_db.get_setting('nullbr_config') or {}

class P115Service:
    _instance = None
    _lock = threading.Lock()
    _client = None
    _last_request_time = 0
    _cookies_cache = None

    @classmethod
    def get_client(cls):
        """è·å–å…¨å±€å”¯ä¸€çš„ P115Client å®ä¾‹ (å¸¦è‡ªåŠ¨é‡è½½å’Œé™æµ)"""
        if P115Client is None:
            raise ImportError("æœªå®‰è£… p115client")

        # è·å–é…ç½®
        config = settings_db.get_setting('nullbr_config') or {}
        cookies = config.get('p115_cookies')
        
        if not cookies:
            return None

        with cls._lock:
            # å¦‚æœ Cookies å˜äº†ï¼Œæˆ–è€…å®¢æˆ·ç«¯è¿˜æ²¡åˆå§‹åŒ–ï¼Œå°±é‡æ–°åˆå§‹åŒ–
            if cls._client is None or cookies != cls._cookies_cache:
                try:
                    cls._client = P115Client(cookies)
                    cls._cookies_cache = cookies
                    logger.debug("  âœ… P115Client å®ä¾‹å·²(é‡æ–°)åˆå§‹åŒ–")
                except Exception as e:
                    logger.error(f"  âŒ P115Client åˆå§‹åŒ–å¤±è´¥: {e}")
                    return None
            
            # â˜…â˜…â˜… å…¨å±€é™æµé€»è¾‘ â˜…â˜…â˜…
            interval = int(config.get('request_interval', 5))
            current_time = time.time()
            elapsed = current_time - cls._last_request_time
            
            if elapsed < interval:
                sleep_time = interval - elapsed
                # åªæœ‰ç­‰å¾…æ—¶é—´è¶…è¿‡1ç§’æ‰æ‰“å°æ—¥å¿—ï¼Œé¿å…åˆ·å±
                if sleep_time > 1:
                    logger.debug(f"  â³ [115é™æµ] å…¨å±€ç­‰å¾… {sleep_time:.2f} ç§’...")
                time.sleep(sleep_time)
            
            cls._last_request_time = time.time()
            
            return cls._client

    @classmethod
    def get_cookies(cls):
        config = settings_db.get_setting('nullbr_config') or {}
        return config.get('p115_cookies')
    
_directory_cid_cache = {} # å…¨å±€ç›®å½• CID ç¼“å­˜ï¼Œkey æ ¼å¼: f"{parent_cid}_{dir_name}"
class SmartOrganizer:
    def __init__(self, client, tmdb_id, media_type, original_title):
        self.client = client
        self.tmdb_id = tmdb_id
        self.media_type = media_type
        self.original_title = original_title
        self.api_key = config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_TMDB_API_KEY)

        self.studio_map = settings_db.get_setting('studio_mapping') or utils.DEFAULT_STUDIO_MAPPING
        self.keyword_map = settings_db.get_setting('keyword_mapping') or utils.DEFAULT_KEYWORD_MAPPING
        self.rating_map = settings_db.get_setting('rating_mapping') or utils.DEFAULT_RATING_MAPPING
        self.rating_priority = settings_db.get_setting('rating_priority') or utils.DEFAULT_RATING_PRIORITY

        self.raw_metadata = self._fetch_raw_metadata()
        self.details = self.raw_metadata
        self.rules = settings_db.get_setting('nullbr_sorting_rules') or []

    def _fetch_raw_metadata(self):
        """
        è·å– TMDb åŸå§‹å…ƒæ•°æ® (ID/Code)ï¼Œä¸è¿›è¡Œä»»ä½•ä¸­æ–‡è½¬æ¢ã€‚
        """
        if not self.api_key: return {}

        data = {
            'genre_ids': [],
            'country_codes': [],
            'lang_code': None,
            'company_ids': [],
            'network_ids': [],
            'keyword_ids': [],
            'rating_label': 'æœªçŸ¥' # åˆ†çº§æ˜¯ç‰¹ä¾‹ï¼Œå¿…é¡»è®¡ç®—å‡ºæ ‡ç­¾æ‰èƒ½åŒ¹é…
        }

        try:
            raw_details = {}
            if self.media_type == 'tv':
                raw_details = tmdb.get_tv_details(
                    self.tmdb_id, self.api_key,
                    append_to_response="keywords,content_ratings,networks"
                )
            else:
                raw_details = tmdb.get_movie_details(
                    self.tmdb_id, self.api_key,
                    append_to_response="keywords,release_dates"
                )

            if not raw_details: return {}

            # 1. åŸºç¡€ ID/Code æå–
            data['genre_ids'] = [g.get('id') for g in raw_details.get('genres', [])]
            data['country_codes'] = [c.get('iso_3166_1') for c in raw_details.get('production_countries', [])]
            if not data['country_codes'] and raw_details.get('origin_country'):
                data['country_codes'] = raw_details.get('origin_country')

            data['lang_code'] = raw_details.get('original_language')

            data['company_ids'] = [c.get('id') for c in raw_details.get('production_companies', [])]
            data['network_ids'] = [n.get('id') for n in raw_details.get('networks', [])] if self.media_type == 'tv' else []

            # 2. å…³é”®è¯ ID æå–
            kw_container = raw_details.get('keywords', {})
            raw_kw_list = kw_container.get('keywords', []) if self.media_type == 'movie' else kw_container.get('results', [])
            data['keyword_ids'] = [k.get('id') for k in raw_kw_list]

            # 3. åˆ†çº§è®¡ç®— 
            data['rating_label'] = utils.get_rating_label(
                raw_details,
                self.media_type,
                self.rating_map,
                self.rating_priority
            )

            # è¡¥å……æ ‡é¢˜æ—¥æœŸä¾›é‡å‘½å
            data['title'] = raw_details.get('title') or raw_details.get('name')
            date_str = raw_details.get('release_date') or raw_details.get('first_air_date')
            data['date'] = date_str
            data['year'] = 0
            
            if date_str and len(str(date_str)) >= 4:
                try:
                    data['year'] = int(str(date_str)[:4])
                except: 
                    pass
            
            # æ‰“å°è°ƒè¯•æ—¥å¿—ï¼Œç¡®è®¤å¹´ä»½æ˜¯å¦è·å–æˆåŠŸ
            # if str(self.tmdb_id) == '172752':
            #     logger.info(f"  ğŸ“… [è°ƒè¯•] ID:172752 è§£æå¹´ä»½: {data['year']} (åŸå§‹æ—¥æœŸ: {date_str})")

            return data

        except Exception as e:
            logger.warning(f"  âš ï¸ [æ•´ç†] è·å–åŸå§‹å…ƒæ•°æ®å¤±è´¥: {e}", exc_info=True)
            return {}

    def _match_rule(self, rule):
        """
        è§„åˆ™åŒ¹é…é€»è¾‘ï¼š
        - æ ‡å‡†å­—æ®µï¼šç›´æ¥æ¯”å¯¹ ID/Code
        - é›†åˆå­—æ®µï¼ˆå·¥ä½œå®¤/å…³é”®è¯ï¼‰ï¼šé€šè¿‡ Label åæŸ¥ Config ä¸­çš„ ID åˆ—è¡¨ï¼Œå†æ¯”å¯¹ TMDb ID
        """
        if not self.raw_metadata: return False

        # 1. åª’ä½“ç±»å‹
        if rule.get('media_type') and rule['media_type'] != 'all':
            if rule['media_type'] != self.media_type: return False

        # 2. ç±»å‹ (Genres) - ID åŒ¹é…
        if rule.get('genres'):
            # rule['genres'] å­˜çš„æ˜¯ ID åˆ—è¡¨ (å¦‚ [16, 35])
            # self.raw_metadata['genre_ids'] æ˜¯ TMDb ID åˆ—è¡¨
            # åªè¦æœ‰ä¸€ä¸ªäº¤é›†å°±ç®—å‘½ä¸­
            rule_ids = [int(x) for x in rule['genres']]
            if not any(gid in self.raw_metadata['genre_ids'] for gid in rule_ids): return False

        # 3. å›½å®¶ (Countries) - Code åŒ¹é…
        if rule.get('countries'):
            # rule['countries'] å­˜çš„æ˜¯ Code (å¦‚ ['US', 'CN'])
            if not any(c in self.raw_metadata['country_codes'] for c in rule['countries']): return False

        # 4. è¯­è¨€ (Languages) - Code åŒ¹é…
        if rule.get('languages'):
            if self.raw_metadata['lang_code'] not in rule['languages']: return False

        # 5. å·¥ä½œå®¤ (Studios) - Label -> ID åŒ¹é…
        if rule.get('studios'):
            # rule['studios'] å­˜çš„æ˜¯ Label (å¦‚ ['æ¼«å¨', 'Netflix'])
            # æˆ‘ä»¬éœ€è¦éå†è¿™äº› Labelï¼Œå» self.studio_map é‡Œæ‰¾å¯¹åº”çš„ ID
            target_ids = set()
            for label in rule['studios']:
                # æ‰¾åˆ°é…ç½®é¡¹
                config_item = next((item for item in self.studio_map if item['label'] == label), None)
                if config_item:
                    target_ids.update(config_item.get('company_ids', []))
                    target_ids.update(config_item.get('network_ids', []))

            # æ£€æŸ¥ TMDb çš„ company/network ID æ˜¯å¦åœ¨ target_ids ä¸­
            has_company = any(cid in target_ids for cid in self.raw_metadata['company_ids'])
            has_network = any(nid in target_ids for nid in self.raw_metadata['network_ids'])

            if not (has_company or has_network): return False

        # 6. å…³é”®è¯ (Keywords) - Label -> ID åŒ¹é…
        if rule.get('keywords'):
            target_ids = set()
            for label in rule['keywords']:
                config_item = next((item for item in self.keyword_map if item['label'] == label), None)
                if config_item:
                    target_ids.update(config_item.get('ids', []))

            # å…¼å®¹å­—ç¬¦ä¸²/æ•°å­— ID
            tmdb_kw_ids = [int(k) for k in self.raw_metadata['keyword_ids']]
            target_ids_int = [int(k) for k in target_ids]

            if not any(kid in target_ids_int for kid in tmdb_kw_ids): return False

        # 7. åˆ†çº§ (Rating) - Label åŒ¹é…
        if rule.get('ratings'):
            if self.raw_metadata['rating_label'] not in rule['ratings']: return False

        # 8. å¹´ä»½ (Year) 
        year_min = rule.get('year_min')
        year_max = rule.get('year_max')
        
        if year_min or year_max:
            current_year = self.raw_metadata.get('year', 0)
            
            # å¦‚æœè·å–ä¸åˆ°å¹´ä»½ï¼Œä¸”è®¾ç½®äº†å¹´ä»½é™åˆ¶ï¼Œåˆ™è§†ä¸ºä¸åŒ¹é…
            if current_year == 0: return False
            
            if year_min and current_year < int(year_min): return False
            if year_max and current_year > int(year_max): return False

        # 9. æ—¶é•¿ (Runtime) 
        # é€»è¾‘ï¼šç”µå½±å– runtimeï¼Œå‰§é›†å– episode_run_time (åˆ—è¡¨å–å¹³å‡æˆ–ç¬¬ä¸€ä¸ª)
        run_min = rule.get('runtime_min')
        run_max = rule.get('runtime_max')

        if run_min or run_max:
            current_runtime = 0
            if self.media_type == 'movie':
                current_runtime = self.details.get('runtime') or 0
            else:
                # å‰§é›†æ—¶é•¿é€šå¸¸æ˜¯ä¸€ä¸ªåˆ—è¡¨ [45, 60]ï¼Œå–ç¬¬ä¸€ä¸ªä½œä¸ºå‚è€ƒ
                runtimes = self.details.get('episode_run_time', [])
                if runtimes and len(runtimes) > 0:
                    current_runtime = runtimes[0]

            # å¦‚æœè·å–ä¸åˆ°æ—¶é•¿ï¼Œä¸”è®¾ç½®äº†é™åˆ¶ï¼Œè§†ä¸ºä¸åŒ¹é…
            if current_runtime == 0: return False

            if run_min and current_runtime < int(run_min): return False
            if run_max and current_runtime > int(run_max): return False

        # 10. è¯„åˆ† (Min Rating) - æ•°å€¼æ¯”è¾ƒ
        if rule.get('min_rating') and float(rule['min_rating']) > 0:
            vote_avg = self.details.get('vote_average', 0)
            if vote_avg < float(rule['min_rating']):
                return False

        return True

    def get_target_cid(self):
        """éå†è§„åˆ™ï¼Œè¿”å›å‘½ä¸­çš„ CIDã€‚æœªå‘½ä¸­è¿”å› None"""
        for rule in self.rules:
            if not rule.get('enabled', True): continue
            if self._match_rule(rule):
                logger.info(f"  ğŸ¯ [115] å‘½ä¸­è§„åˆ™: {rule.get('name')} -> ç›®å½•: {rule.get('dir_name')}")
                return rule.get('cid')
        return None

    def _extract_video_info(self, filename):
        """
        ä»æ–‡ä»¶åæå–è§†é¢‘ä¿¡æ¯ (æ¥æº Â· åˆ†è¾¨ç‡ Â· ç¼–ç  Â· éŸ³é¢‘ Â· åˆ¶ä½œç»„)
        å‚è€ƒæ ¼å¼: BluRay Â· 1080p Â· X264 Â· DDP 7.1 Â· CMCT
        """
        info_tags = []
        name_upper = filename.upper()

        # 1. æ¥æº/è´¨é‡ (Source)
        source = ""
        if re.search(r'REMUX', name_upper): source = 'Remux'
        elif re.search(r'BLU-?RAY|BD', name_upper): source = 'BluRay'
        elif re.search(r'WEB-?DL', name_upper): source = 'WEB-DL'
        elif re.search(r'WEB-?RIP', name_upper): source = 'WEBRip'
        elif re.search(r'HDTV', name_upper): source = 'HDTV'
        elif re.search(r'DVD', name_upper): source = 'DVD'

        # â˜…â˜…â˜… ä¿®å¤ï¼šUHD è¯†åˆ« â˜…â˜…â˜…
        if 'UHD' in name_upper:
            if source == 'BluRay': source = 'UHD BluRay'
            elif not source: source = 'UHD'

        # 2. ç‰¹æ•ˆ (Effect: HDR/DV)
        effect = ""
        is_dv = re.search(r'(?:^|[\.\s\-\_])(DV|DOVI|DOLBY\s?VISION)(?:$|[\.\s\-\_])', name_upper)
        is_hdr = re.search(r'(?:^|[\.\s\-\_])(HDR|HDR10\+?)(?:$|[\.\s\-\_])', name_upper)

        if is_dv and is_hdr: effect = "HDR DV"
        elif is_dv: effect = "DV"
        elif is_hdr: effect = "HDR"

        if source:
            info_tags.append(f"{source} {effect}".strip())
        elif effect:
            info_tags.append(effect)

        # 3. åˆ†è¾¨ç‡ (Resolution)
        res_match = re.search(r'(2160|1080|720|480)[pP]', filename)
        if res_match:
            info_tags.append(res_match.group(0).lower())
        elif '4K' in name_upper:
            info_tags.append('2160p')

        # 4. ç¼–ç  (Codec)
        codec = ""
        if re.search(r'[HX]265|HEVC', name_upper): info_tags.append('x265')
        elif re.search(r'[HX]264|AVC', name_upper): info_tags.append('H264')
        elif re.search(r'AV1', name_upper): info_tags.append('AV1')
        elif re.search(r'MPEG-?2', name_upper): info_tags.append('MPEG2')
        # æ¯”ç‰¹ç‡æå– (Bit Depth) 
        bit_depth = ""
        bit_match = re.search(r'(\d{1,2})BIT', name_upper)
        if bit_match:
            bit_depth = f"{bit_match.group(1)}bit" # ç»Ÿä¸€æ ¼å¼ä¸ºå°å†™ bit

        # å°†ç¼–ç å’Œæ¯”ç‰¹ç‡ç»„åˆï¼Œæ¯”å¦‚ "H265 10bit" æˆ–å•ç‹¬ "H265"
        if codec:
            full_codec = f"{codec} {bit_depth}".strip()
            info_tags.append(full_codec)
        elif bit_depth:
            info_tags.append(bit_depth)

        # 5. éŸ³é¢‘ (Audio) - â˜…â˜…â˜… ä¿®å¤é‡ç‚¹ â˜…â˜…â˜…
        audio_info = []
        
        # (1) ä¼˜å…ˆåŒ¹é…å¸¦æ•°å­—çš„éŸ³è½¨ (2Audio, 3Audios) å¹¶ç»Ÿä¸€æ ¼å¼ä¸º "xAudios"
        # æ­£åˆ™è¯´æ˜: åŒ¹é…è¾¹ç•Œ + æ•°å­— + ç©ºæ ¼(å¯é€‰) + Audio + s(å¯é€‰) + è¾¹ç•Œ
        num_audio_match = re.search(r'\b(\d+)\s?Audios?\b', name_upper, re.IGNORECASE)
        if num_audio_match:
            # ç»Ÿä¸€æ ¼å¼åŒ–ä¸º: æ•°å­— + Audios (ä¾‹å¦‚: 2Audios)
            audio_info.append(f"{num_audio_match.group(1)}Audios")
        else:
            # (2) å¦‚æœæ²¡æœ‰æ•°å­—éŸ³è½¨ï¼Œå†åŒ¹é… Multi/Dual ç­‰é€šç”¨æ ‡ç­¾
            if re.search(r'\b(Multi|åŒè¯­|å¤šéŸ³è½¨|Dual-Audio)\b', name_upper, re.IGNORECASE):
                audio_info.append('Multi')

        # (3) å…¶ä»–å…·ä½“éŸ³é¢‘ç¼–ç 
        if re.search(r'ATMOS', name_upper): audio_info.append('Atmos')
        elif re.search(r'TRUEHD', name_upper): audio_info.append('TrueHD')
        elif re.search(r'DTS-?HD(\s?MA)?', name_upper): audio_info.append('DTS-HD')
        elif re.search(r'DTS', name_upper): audio_info.append('DTS')
        elif re.search(r'DDP|EAC3|DOLBY\s?DIGITAL\+', name_upper): audio_info.append('DDP')
        elif re.search(r'AC3|DD', name_upper): audio_info.append('AC3')
        elif re.search(r'AAC', name_upper): audio_info.append('AAC')
        elif re.search(r'FLAC', name_upper): audio_info.append('FLAC')
        elif re.search(r'OPUS', name_upper): audio_info.append('Opus')
        
        chan_match = re.search(r'\b(7\.1|5\.1|2\.0)\b', filename)
        if chan_match:
            audio_info.append(chan_match.group(1))
            
        if audio_info:
            info_tags.append(" ".join(audio_info))

        # æµåª’ä½“å¹³å°è¯†åˆ«
        # åŒ¹é… NF, AMZN, DSNP, HMAX, HULU, NETFLIX, DISNEY+, APPLETV+
        stream_match = re.search(r'\b(NF|AMZN|DSNP|HMAX|HULU|NETFLIX|DISNEY\+|APPLETV\+|B-GLOBAL)\b', name_upper)
        if stream_match:
            info_tags.append(stream_match.group(1))

        # 6. å‘å¸ƒç»„ (Release Group)
        group_found = False
        try:
            from tasks import helpers
            for group_name, patterns in helpers.RELEASE_GROUPS.items():
                for pattern in patterns:
                    try:
                        match = re.search(pattern, filename, re.IGNORECASE)
                        if match:
                            info_tags.append(match.group(0))
                            group_found = True
                            break
                    except: pass
                if group_found: break

            if not group_found:
                name_no_ext = os.path.splitext(filename)[0]
                match_suffix = re.search(r'-([a-zA-Z0-9]+)$', name_no_ext)
                if match_suffix:
                    possible_group = match_suffix.group(1)
                    if len(possible_group) > 2 and possible_group.upper() not in ['1080P', '2160P', '4K', 'HDR', 'H265', 'H264']:
                        info_tags.append(possible_group)
        except ImportError:
            pass

        return " Â· ".join(info_tags) if info_tags else ""

    def _rename_file_node(self, file_node, new_base_name, year=None, is_tv=False):
        """
        é‡å‘½åå•ä¸ªæ–‡ä»¶èŠ‚ç‚¹
        ä¿®å¤ï¼šå­—å¹•æ–‡ä»¶å…ˆå‰¥ç¦»è¯­è¨€æ ‡ç­¾ï¼Œå†æå–Tagsï¼Œç¡®ä¿èƒ½è¯†åˆ«åˆ°è¢«è¯­è¨€æ ‡ç­¾æŒ¡ä½çš„å‘å¸ƒç»„ã€‚
        """
        original_name = file_node.get('n', '')
        if '.' not in original_name: return original_name, None

        # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
        parts = original_name.rsplit('.', 1)
        name_body = parts[0]
        ext = parts[1].lower()

        is_sub = ext in ['srt', 'ass', 'ssa', 'sub', 'vtt', 'sup']

        # -------------------------------------------------
        # 1. ä¼˜å…ˆè®¡ç®—å­—å¹•è¯­è¨€åç¼€ (ä¸ºäº†åç»­å‰¥ç¦»å®ƒ)
        # -------------------------------------------------
        lang_suffix = ""
        if is_sub:
            # å¸¸è§è¯­è¨€ä»£ç ç™½åå•
            lang_keywords = [
                'zh', 'cn', 'tw', 'hk', 'en', 'jp', 'kr',
                'chs', 'cht', 'eng', 'jpn', 'kor', 'fre', 'spa',
                'default', 'forced', 'tc', 'sc'
            ]

            # ç­–ç•¥A: æ£€æŸ¥æ–‡ä»¶åæœ€åä¸€æ®µ (Movie.chs.srt)
            sub_parts = name_body.split('.')
            if len(sub_parts) > 1:
                last_part = sub_parts[-1].lower()
                if last_part in lang_keywords or '-' in last_part:
                    lang_suffix = f".{sub_parts[-1]}" # ä¿æŒåŸå¤§å°å†™

            # ç­–ç•¥B: æ­£åˆ™æœç´¢
            if not lang_suffix:
                match = re.search(r'(?:\.|-|_|\s)(chs|cht|zh-cn|zh-tw|eng|jpn|kor|tc|sc)(?:\.|-|_|$)', name_body, re.IGNORECASE)
                if match:
                    lang_suffix = f".{match.group(1)}"

        # -------------------------------------------------
        # 2. æå– Tags (å…³é”®ä¿®å¤æ­¥éª¤)
        # -------------------------------------------------
        tag_suffix = ""
        try:
            # æ„é€ ç”¨äºæå–ä¿¡æ¯çš„â€œæœç´¢åâ€
            search_name = original_name

            if is_sub:
                # å¦‚æœæ˜¯å­—å¹•ï¼ŒæŠŠè¯­è¨€åç¼€å’Œæ‰©å±•åéƒ½å»æ‰ï¼Œä¼ªè£…æˆçº¯è§†é¢‘æ–‡ä»¶å
                if lang_suffix and name_body.endswith(lang_suffix):
                    # å»æ‰ .zh
                    clean_body = name_body[:-len(lang_suffix)]
                    search_name = f"{clean_body}.mkv" # è¡¥ä¸ªå‡åç¼€é˜²æŠ¥é”™
                else:
                    # å¦‚æœæ²¡æ‰¾åˆ°æ ‡å‡†åç¼€ï¼Œç›´æ¥ç”¨ name_body
                    search_name = f"{name_body}.mkv"

            video_info = self._extract_video_info(search_name)
            if video_info:
                tag_suffix = f" Â· {video_info}"
        except Exception as e:
            # logger.debug(f"Tagsæå–å¤±è´¥: {e}")
            pass

        # -------------------------------------------------
        # 3. æ„å»ºæ–°æ–‡ä»¶å
        # -------------------------------------------------
        if is_tv:
            # === å‰§é›†æ¨¡å¼ ===
            pattern = r'(?:s|S)(\d{1,2})(?:e|E)(\d{1,2})|Ep?(\d{1,2})|ç¬¬(\d{1,3})[é›†è¯]'
            match = re.search(pattern, original_name)
            if match:
                s, e, ep_only, zh_ep = match.groups()
                season_num = int(s) if s else 1
                episode_num = int(e) if e else (int(ep_only) if ep_only else int(zh_ep))

                s_str = f"S{season_num:02d}"
                e_str = f"E{episode_num:02d}"

                # æ ¼å¼ï¼šTitle - S01E01 Â· Tags[.Lang].ext
                new_name = f"{new_base_name} - {s_str}{e_str}{tag_suffix}{lang_suffix}.{ext}"
                return new_name, season_num
            else:
                return original_name, None
        else:
            # === ç”µå½±æ¨¡å¼ ===
            movie_base = f"{new_base_name} ({year})" if year else new_base_name

            # æ ¼å¼ï¼šTitle (Year) Â· Tags[.Lang].ext
            new_name = f"{movie_base}{tag_suffix}{lang_suffix}.{ext}"

            return new_name, None

    def _scan_files_recursively(self, cid, depth=0, max_depth=3):
        """é€’å½’æ‰«ææ–‡ä»¶å¤¹ï¼Œè¿”å›æ‰€æœ‰æ–‡ä»¶çš„æ‰å¹³åˆ—è¡¨"""
        all_files = []
        if depth > max_depth: return []

        try:
            # limit è°ƒå¤§ä¸€ç‚¹ï¼Œé˜²æ­¢æ–‡ä»¶è¿‡å¤šæ¼æ‰
            res = self.client.fs_files({'cid': cid, 'limit': 2000})
            if res.get('data'):
                for item in res['data']:
                    # å¦‚æœæ˜¯æ–‡ä»¶ (æœ‰ fid)
                    if item.get('fid'):
                        all_files.append(item)
                    # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ (æ—  fid)ï¼Œä¸”æœªè¾¾æ·±åº¦é™åˆ¶ï¼Œé€’å½’
                    elif item.get('cid'):
                        sub_files = self._scan_files_recursively(item.get('cid'), depth + 1, max_depth)
                        all_files.extend(sub_files)
        except Exception as e:
            logger.warning(f"  âš ï¸ æ‰«æç›®å½•å‡ºé”™ (CID: {cid}): {e}")

        return all_files

    def _is_junk_file(self, filename):
        """
        æ£€æŸ¥æ˜¯å¦ä¸ºåƒåœ¾æ–‡ä»¶/æ ·æœ¬/èŠ±çµ® (åŸºäº MP è§„åˆ™)
        """
        # åƒåœ¾æ–‡ä»¶æ­£åˆ™åˆ—è¡¨ (åˆå¹¶äº†é€šç”¨è§„åˆ™å’Œä½ æä¾›çš„ MP è§„åˆ™)
        junk_patterns = [
            # åŸºç¡€å…³é”®è¯
            r'(?i)\b(sample|trailer|featurette|bonus)\b',

            # MP è§„åˆ™é›†
            r'(?i)Special Ending Movie',
            r'(?i)\[((TV|BD|\bBlu-ray\b)?\s*CM\s*\d{2,3})\]',
            r'(?i)\[Teaser.*?\]',
            r'(?i)\[PV.*?\]',
            r'(?i)\[NC[OPED]+.*?\]',
            r'(?i)\[S\d+\s+Recap(\s+\d+)?\]',
            r'(?i)Menu',
            r'(?i)Preview',
            r'(?i)\b(CDs|SPs|Scans|Bonus|æ˜ åƒç‰¹å…¸|æ˜ åƒ|specials|ç‰¹å…¸CD|Menu|Logo|Preview|/mv)\b',
            r'(?i)\b(NC)?(Disc|ç‰‡å¤´|OP|SP|ED|Advice|Trailer|BDMenu|ç‰‡å°¾|PV|CM|Preview|MENU|Info|EDPV|SongSpot|BDSpot)(\d{0,2}|_ALL)\b',
            r'(?i)WiKi\.sample'
        ]

        for pattern in junk_patterns:
            if re.search(pattern, filename):
                return True
        return False

    def execute(self, root_item, target_cid):
        """
        æ‰§è¡Œæ•´ç†
        """
        # 1. å‡†å¤‡æ ‡å‡†åç§°
        title = self.details.get('title') or self.original_title
        date_str = self.details.get('date') or ''
        year = date_str[:4] if date_str else ''

        safe_title = re.sub(r'[\\/:*?"<>|]', '', title).strip()
        std_root_name = f"{safe_title} ({year}) {{tmdb={self.tmdb_id}}}" if year else f"{safe_title} {{tmdb={self.tmdb_id}}}"

        source_root_id = root_item.get('fid') or root_item.get('cid')
        is_source_file = bool(root_item.get('fid'))

        dest_parent_cid = target_cid if (target_cid and str(target_cid) != '0') else root_item.get('cid')

        MIN_VIDEO_SIZE = 10 * 1024 * 1024

        video_exts = ['mp4', 'mkv', 'avi', 'ts', 'iso', 'rmvb', 'wmv', 'mov', 'm2ts']
        sub_exts = ['srt', 'ass', 'ssa', 'sub', 'vtt', 'sup']

        logger.info(f"  ğŸš€ [115] å¼€å§‹æ•´ç†: {root_item.get('n')} -> {std_root_name}")

        # ==================================================
        # æ­¥éª¤ A: è·å–æˆ–åˆ›å»ºç›®æ ‡æ ‡å‡†æ–‡ä»¶å¤¹ (å¸¦ç¼“å­˜ä¼˜åŒ–)
        # ==================================================
        final_home_cid = None
        
        # 1. æ„å»ºç¼“å­˜ Key (çˆ¶ç›®å½•CID + ç›®æ ‡ç›®å½•å)
        cache_key = f"{dest_parent_cid}-{std_root_name}"
        
        # 2. å…ˆæŸ¥ç¼“å­˜
        if cache_key in _directory_cid_cache:
            final_home_cid = _directory_cid_cache[cache_key]
            logger.info(f"  âš¡ [ç¼“å­˜å‘½ä¸­] ç›®å½• CID: {final_home_cid}")
        
        # 3. ç¼“å­˜æœªå‘½ä¸­ï¼Œèµ° API (ä¹è§‚é”ç­–ç•¥)
        if not final_home_cid:
            # å°è¯•ç›´æ¥åˆ›å»º
            mk_res = self.client.fs_mkdir(std_root_name, dest_parent_cid)
            
            if mk_res.get('state'):
                # åˆ›å»ºæˆåŠŸ
                final_home_cid = mk_res.get('cid')
                logger.info(f"  ğŸ†• åˆ›å»ºæ–°ç›®å½•æˆåŠŸ: {std_root_name}")
                # â˜…â˜…â˜… å†™å…¥ç¼“å­˜ â˜…â˜…â˜…
                if self.media_type == 'tv': # åªæœ‰å‰§é›†æ¨¡å¼æ‰ç¼“å­˜ç›®å½• CIDï¼Œå› ä¸ºç”µå½±æ¨¡å¼å¯èƒ½æ¯ä¸ªæ–‡ä»¶å¤¹éƒ½ä¸ä¸€æ ·
                    _directory_cid_cache[cache_key] = final_home_cid
                    logger.info(f"  âš¡ [ç¼“å­˜æ›´æ–°] ç›®å½• CID: {final_home_cid}")
            else:
                # åˆ›å»ºå¤±è´¥ï¼Œå›é€€æœç´¢
                try:
                    search_res = self.client.fs_files({
                        'cid': dest_parent_cid, 
                        'search_value': std_root_name, 
                        'limit': 1000, 
                    })
                    if search_res.get('data'):
                        for item in search_res['data']:
                            if item.get('n') == std_root_name and (item.get('ico') == 'folder' or not item.get('fid')):
                                final_home_cid = item.get('cid')
                                logger.info(f"  ğŸ“‚ å‘ç°å·²å­˜åœ¨çš„ç›®å½•: {std_root_name}")
                                if self.media_type == 'tv': # åªæœ‰å‰§é›†æ¨¡å¼æ‰ç¼“å­˜ç›®å½• CIDï¼Œå› ä¸ºç”µå½±æ¨¡å¼å¯èƒ½æ¯ä¸ªæ–‡ä»¶å¤¹éƒ½ä¸ä¸€æ ·
                                    _directory_cid_cache[cache_key] = final_home_cid
                                    logger.info(f"  âš¡ [ç¼“å­˜æ›´æ–°] ç›®å½• CID: {final_home_cid}")
                                break
                except Exception as e:
                    logger.warning(f"  âš ï¸ æŸ¥æ‰¾ç›®å½•å¼‚å¸¸: {e}")

        # å¦‚æœç»è¿‡åˆ›å»ºå’ŒæŸ¥æ‰¾éƒ½æ‹¿ä¸åˆ° CIDï¼Œè¯´æ˜çœŸçš„å‡ºé—®é¢˜äº†
        if not final_home_cid:
            logger.error(f"  âŒ æ— æ³•è·å–ç›®æ ‡ç›®å½• CID (åˆ›å»ºå¤±è´¥ä¸”æŸ¥æ‰¾æœªæœ): {std_root_name}")
            return False

        # ==================================================
        # æ­¥éª¤ B: æ‰«ææºæ–‡ä»¶
        # ==================================================
        candidates = []
        if is_source_file:
            candidates.append(root_item)
        else:
            candidates = self._scan_files_recursively(source_root_id, max_depth=3)

        if not candidates:
            logger.warning("  âš ï¸ æºç›®å½•ä¸ºç©ºæˆ–æœªæ‰«æåˆ°æ–‡ä»¶ã€‚")
            return True

        # ==================================================
        # æ­¥éª¤ C: ç­›é€‰ -> é‡å‘½å -> ç§»åŠ¨
        # ==================================================
        season_folders_cache = {}
        moved_count = 0

        for file_item in candidates:
            time.sleep(random.uniform(0.5, 1.0))
            fid = file_item.get('fid')
            file_name = file_item.get('n', '')
            ext = file_name.split('.')[-1].lower() if '.' in file_name else ''

            # ä¼˜å…ˆè¿›è¡Œåƒåœ¾è¯è¿‡æ»¤
            if self._is_junk_file(file_name):
                logger.info(f"  ğŸ—‘ï¸ [è¿‡æ»¤] å‘½ä¸­å±è”½è¯ï¼Œè·³è¿‡åƒåœ¾æ–‡ä»¶: {file_name}")
                continue

            # å¤§å°è§£æ
            raw_size = file_item.get('s')
            if raw_size is None: raw_size = file_item.get('size')
            file_size = _parse_115_size(raw_size)

            is_video = ext in video_exts
            is_sub = ext in sub_exts

            if not (is_video or is_sub): continue

            # è¿‡æ»¤å°æ · (å¤§å°å…œåº•)
            # å¦‚æœæ­£åˆ™æ²¡æ‹¦ä½ï¼Œä½†æ–‡ä»¶å¾ˆå°ï¼Œä¾ç„¶ä¼šè¢«è¿™é‡Œæ‹¦ä½
            if is_video:
                if 0 < file_size < MIN_VIDEO_SIZE:
                    logger.info(f"  ğŸ—‘ï¸ [è¿‡æ»¤] è·³è¿‡å°è§†é¢‘ (Size): {file_name}")
                    continue
                elif file_size == 0:
                    # å¦‚æœè§£æå‡ºæ¥æ˜¯0ï¼Œå¯èƒ½æ˜¯APIé—®é¢˜ï¼Œæ‰“å°æ—¥å¿—ä½†ä¿ç•™æ–‡ä»¶
                    logger.debug(f"  âš ï¸ [æ³¨æ„] æ–‡ä»¶å¤§å°è§£æä¸º0 (Raw: {raw_size})ï¼Œå¼ºåˆ¶ä¿ç•™: {file_name}")
                else:
                    logger.debug(f"  ğŸ“„ æ–‡ä»¶: {file_name}, å¤§å°: {file_size/1024/1024:.2f} MB")

            # 2. è®¡ç®—æ–°æ–‡ä»¶å
            new_filename = file_name
            season_num = None

            # è§†é¢‘å’Œå­—å¹•éƒ½å‚ä¸é‡å‘½åè®¡ç®—
            if is_video or is_sub:
                try:
                    new_filename, season_num = self._rename_file_node(
                        file_item,
                        safe_title,       # åŸºç¡€æ ‡é¢˜ (ä¸å«å¹´ä»½)
                        year=year,        # ä¼ å…¥å¹´ä»½
                        is_tv=(self.media_type=='tv')
                    )
                except Exception as e:
                    logger.error(f"  âŒ é‡å‘½åè®¡ç®—å‡ºé”™: {e}")
                    new_filename = file_name

            # 3. æ‰§è¡Œé‡å‘½å (åœ¨æºä½ç½®)
            if new_filename != file_name:
                rename_res = self.client.fs_rename((fid, new_filename))
                if rename_res.get('state'):
                    logger.info(f"  âœï¸ [é‡å‘½å] {file_name} -> {new_filename}")
                else:
                    logger.warning(f"  âš ï¸ é‡å‘½åå¤±è´¥: {file_name}")
                    new_filename = file_name

            # 4. ç¡®å®šç§»åŠ¨çš„ç›®æ ‡æ–‡ä»¶å¤¹
            target_folder_cid = final_home_cid

            # åªæœ‰å‰§é›†ä¸”æˆåŠŸè§£æå‡ºå­£å·æ—¶ï¼Œæ‰æ”¾å…¥ Season æ–‡ä»¶å¤¹
            if self.media_type == 'tv' and season_num is not None:
                if season_num not in season_folders_cache:
                    s_name = f"Season {season_num:02d}"
                    s_mk = self.client.fs_mkdir(s_name, final_home_cid)
                    if s_mk.get('state'):
                        season_folders_cache[season_num] = s_mk.get('cid')
                    else:
                        s_search = self.client.fs_files({'cid': final_home_cid, 'search_value': s_name, 'limit': 10})
                        if s_search.get('data'):
                            for item in s_search['data']:
                                if item.get('n') == s_name and not item.get('fid'):
                                    season_folders_cache[season_num] = item.get('cid')
                                    break

                if season_folders_cache.get(season_num):
                    target_folder_cid = season_folders_cache[season_num]

            # 5. æ‰§è¡Œç§»åŠ¨
            move_res = self.client.fs_move(fid, target_folder_cid)
            if move_res.get('state'):
                moved_count += 1
            else:
                logger.error(f"  âŒ ç§»åŠ¨æ–‡ä»¶å¤±è´¥: {new_filename}")

        # ==================================================
        # æ­¥éª¤ D: é”€æ¯æºç›®å½•
        # ==================================================
        if not is_source_file:
            if moved_count > 0:
                logger.info(f"  ğŸ§¹ [æ¸…ç†] åˆ é™¤æºç›®å½•: {root_item.get('n')}")
                self.client.fs_delete([source_root_id])
            else:
                logger.warning("  âš ï¸ æœªç§»åŠ¨ä»»ä½•æœ‰æ•ˆæ–‡ä»¶ï¼Œä¿ç•™æºç›®å½•ä»¥é˜²æ•°æ®ä¸¢å¤±ã€‚")

        logger.info(f"  âœ… [æ•´ç†] å®Œæˆã€‚å…±è¿ç§» {moved_count} ä¸ªæ–‡ä»¶ã€‚")
        return True

def _parse_115_size(size_val):
    """
    ç»Ÿä¸€è§£æ 115 è¿”å›çš„æ–‡ä»¶å¤§å°ä¸ºå­—èŠ‚(Int)
    æ”¯æŒ: 12345(int), "12345"(str), "1.2GB", "500KB"
    """
    try:
        if size_val is None: return 0

        # 1. å¦‚æœå·²ç»æ˜¯æ•°å€¼ (115 API 's' å­—æ®µé€šå¸¸æ˜¯ int)
        if isinstance(size_val, (int, float)):
            return int(size_val)

        # 2. å¦‚æœæ˜¯å­—ç¬¦ä¸²
        if isinstance(size_val, str):
            s = size_val.strip()
            if not s: return 0
            # çº¯æ•°å­—å­—ç¬¦ä¸²
            if s.isdigit():
                return int(s)

            s_upper = s.upper().replace(',', '')
            mult = 1
            if 'TB' in s_upper: mult = 1024**4
            elif 'GB' in s_upper: mult = 1024**3
            elif 'MB' in s_upper: mult = 1024**2
            elif 'KB' in s_upper: mult = 1024

            match = re.search(r'([\d\.]+)', s_upper)
            if match:
                return int(float(match.group(1)) * mult)
    except Exception:
        pass
    return 0

def _perform_cms_notify():
    """
    çœŸæ­£æ‰§è¡Œ CMS é€šçŸ¥çš„å‡½æ•° (è¢«å®šæ—¶å™¨è°ƒç”¨)
    """
    config = get_config()
    cms_url = config.get('cms_url')
    cms_token = config.get('cms_token')

    if not cms_url or not cms_token:
        return

    cms_url = cms_url.rstrip('/')
    enable_smart_organize = config.get('enable_smart_organize', False)

    # æ ¹æ®æ¨¡å¼é€‰æ‹©å‚æ•°
    if enable_smart_organize:
        api_url = f"{cms_url}/api/sync/lift_by_token"
        params = {"type": "lift_sync", "token": cms_token}
        log_msg = "å¢é‡åŒæ­¥"
    else:
        api_url = f"{cms_url}/api/sync/lift_by_token"
        params = {"type": "auto_organize", "token": cms_token}
        log_msg = "è‡ªåŠ¨æ•´ç†"

    logger.info(f"  ğŸ“£ [CMS] é˜²æŠ–ç»“æŸï¼Œå¼€å§‹: {log_msg} ...")

    try:
        response = requests.get(api_url, params=params, timeout=10)
        response.raise_for_status()
        res_json = response.json()
        if res_json.get('code') == 200 or res_json.get('success'):
            logger.info(f"  âœ… CMS é€šçŸ¥æˆåŠŸ: {res_json.get('msg', 'OK')}")
        else:
            logger.warning(f"  âš ï¸ CMS é€šçŸ¥è¿”å›å¼‚å¸¸: {res_json}")
    except Exception as e:
        logger.warning(f"  âš ï¸ CMS é€šçŸ¥å‘é€å¤±è´¥: {e}")


def notify_cms_scan():
    """
    é€šçŸ¥ CMS æ‰§è¡Œç›®å½•æ•´ç† (é˜²æŠ–å…¥å£)
    æœºåˆ¶ï¼šæ¯æ¬¡è°ƒç”¨éƒ½ä¼šé‡ç½®è®¡æ—¶å™¨ï¼Œåªæœ‰é™é»˜ 60 ç§’åæ‰ä¼šçœŸæ­£å‘é€è¯·æ±‚ã€‚
    """
    global _cms_timer

    with _cms_lock:
        # å¦‚æœå·²æœ‰è®¡æ—¶å™¨åœ¨è¿è¡Œï¼Œå–æ¶ˆå®ƒ (è¯´æ˜1åˆ†é’Ÿå†…åˆæœ‰æ–°å…¥åº“)
        if _cms_timer is not None:
            _cms_timer.cancel()
            logger.debug("  â³ æ£€æµ‹åˆ°è¿ç»­å…¥åº“ï¼Œé‡ç½® CMS é€šçŸ¥è®¡æ—¶å™¨ (60s)")
        else:
            logger.info("  â³ å¯åŠ¨ CMS é€šçŸ¥è®¡æ—¶å™¨ï¼Œç­‰å¾… 60s æ— æ–°å…¥åº“åå‘é€...")

        # åˆ›å»ºæ–°è®¡æ—¶å™¨ï¼š60ç§’åæ‰§è¡Œ _perform_cms_notify
        _cms_timer = threading.Timer(60.0, _perform_cms_notify)
        _cms_timer.daemon = True # è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹ï¼Œé˜²æ­¢é˜»å¡ä¸»ç¨‹åºé€€å‡º
        _cms_timer.start()

def get_115_account_info():
    """
    æç®€çŠ¶æ€æ£€æŸ¥ï¼šåªéªŒè¯ Cookie æ˜¯å¦æœ‰æ•ˆï¼Œä¸è·å–ä»»ä½•è¯¦æƒ…
    """
    client = P115Service.get_client()
    if not client: raise Exception("æ— æ³•åˆå§‹åŒ– 115 å®¢æˆ·ç«¯")

    config = get_config()
    cookies = config.get('p115_cookies')

    if not cookies:
        raise Exception("æœªé…ç½® Cookies")

    try:
        # å°è¯•åˆ—å‡º 1 ä¸ªæ–‡ä»¶ï¼Œè¿™æ˜¯éªŒè¯ Cookie æœ€å¿«æœ€å‡†çš„æ–¹æ³•
        resp = client.fs_files({'limit': 1})

        if not resp.get('state'):
            raise Exception("Cookie å·²å¤±æ•ˆ")

        # åªè¦æ²¡æŠ¥é”™ï¼Œå°±æ˜¯æœ‰æ•ˆ
        return {
            "valid": True,
            "msg": "Cookie çŠ¶æ€æ­£å¸¸ï¼Œå¯æ­£å¸¸æ¨é€"
        }

    except Exception as e:
        raise Exception("Cookie æ— æ•ˆæˆ–ç½‘ç»œä¸é€š")


def _identify_media_enhanced(filename, forced_media_type=None):
    """
    å¢å¼ºè¯†åˆ«é€»è¾‘ï¼š
    1. æ”¯æŒå¤šç§ TMDb ID æ ‡ç­¾æ ¼å¼: {tmdb=xxx}
    2. æ”¯æŒæ ‡å‡†å‘½åæ ¼å¼: Title (Year)
    3. æ¥æ”¶å¤–éƒ¨å¼ºåˆ¶æŒ‡å®šçš„ç±»å‹ (forced_media_type)ï¼Œä¸å†è½®è¯¢çŒœæµ‹
    
    è¿”å›: (tmdb_id, media_type, title) æˆ– (None, None, None)
    """
    tmdb_id = None
    media_type = 'movie' # é»˜è®¤
    title = filename
    
    # 1. ä¼˜å…ˆæå– TMDb ID æ ‡ç­¾ (æœ€ç¨³)
    match_tag = re.search(r'\{?tmdb(?:id)?[=\-](\d+)\}?', filename, re.IGNORECASE)
    
    if match_tag:
        tmdb_id = match_tag.group(1)
        
        # å¦‚æœå¤–éƒ¨æŒ‡å®šäº†ç±»å‹ï¼Œç›´æ¥ç”¨ï¼›å¦åˆ™çœ‹æ–‡ä»¶åç‰¹å¾
        if forced_media_type:
            media_type = forced_media_type
        elif re.search(r'(?:S\d{1,2}|E\d{1,2}|ç¬¬\d+å­£|Season)', filename, re.IGNORECASE):
            media_type = 'tv'
        
        # æå–æ ‡é¢˜
        clean_name = re.sub(r'\{?tmdb(?:id)?[=\-]\d+\}?', '', filename, flags=re.IGNORECASE).strip()
        match_title = re.match(r'^(.+?)\s*[\(\[]\d{4}[\)\]]', clean_name)
        if match_title:
            title = match_title.group(1).strip()
        else:
            title = clean_name
            
        return tmdb_id, media_type, title

    # 2. å…¶æ¬¡æå–æ ‡å‡†æ ¼å¼ Title (Year)
    match_std = re.match(r'^(.+?)\s+[\(\[](\d{4})[\)\]]', filename)
    if match_std:
        name_part = match_std.group(1).strip()
        year_part = match_std.group(2)
        
        # === å…³é”®ä¿®æ­£ï¼šç±»å‹åˆ¤æ–­é€»è¾‘ ===
        if forced_media_type:
            # å¦‚æœå¤–éƒ¨é€è§†è¿‡ç›®å½•ï¼Œç¡®å®šæ˜¯ TVï¼Œç›´æ¥ä¿¡èµ–
            media_type = forced_media_type
        else:
            # å¦åˆ™æ‰æ ¹æ®æ–‡ä»¶åç‰¹å¾åˆ¤æ–­
            if re.search(r'(?:S\d{1,2}|E\d{1,2}|ç¬¬\d+å­£|Season)', filename, re.IGNORECASE):
                media_type = 'tv'
            else:
                media_type = 'movie'
            
        # å°è¯•é€šè¿‡ TMDb API ç¡®è®¤ ID
        try:
            api_key = config_manager.APP_CONFIG.get(constants.CONFIG_OPTION_TMDB_API_KEY)
            if api_key:
                # ç²¾å‡†æœç´¢ï¼Œä¸è½®è¯¢ï¼Œä¸ççŒœ
                results = tmdb.search_media(
                    query=name_part, 
                    api_key=api_key, 
                    item_type=media_type, 
                    year=year_part
                )
                
                if results and len(results) > 0:
                    best = results[0]
                    return best['id'], media_type, (best.get('title') or best.get('name'))
                else:
                    logger.warning(f"  âš ï¸ TMDb æœªæ‰¾åˆ°èµ„æº: {name_part} ({year_part}) ç±»å‹: {media_type}")

        except Exception as e:
            pass

    return None, None, None


def task_scan_and_organize_115(processor=None):
    """
    [ä»»åŠ¡é“¾] ä¸»åŠ¨æ‰«æ 115 å¾…æ•´ç†ç›®å½•
    - è¯†åˆ«æˆåŠŸ -> å½’ç±»åˆ°ç›®æ ‡ç›®å½•
    - è¯†åˆ«å¤±è´¥ -> ç§»åŠ¨åˆ° 'æœªè¯†åˆ«' ç›®å½•
    â˜… ä¿®å¤ï¼šå¢åŠ å­æ–‡ä»¶æ¢æµ‹é€»è¾‘ï¼Œé˜²æ­¢å‰§é›†æ–‡ä»¶å¤¹å› å‘½åä¸è§„èŒƒè¢«è¯¯åˆ¤ä¸ºç”µå½±
    """
    logger.info("=== å¼€å§‹æ‰§è¡Œ 115 å¾…æ•´ç†ç›®å½•æ‰«æ ===")

    client = P115Service.get_client()
    if not client: raise Exception("æ— æ³•åˆå§‹åŒ– 115 å®¢æˆ·ç«¯")

    config = get_config()
    cookies = config.get('p115_cookies')
    cid_val = config.get('p115_save_path_cid')
    save_val = config.get('p115_save_path_name', 'å¾…æ•´ç†')
    enable_organize = config.get('enable_smart_organize', False)

    if not cookies:
        logger.error("  âš ï¸ æœªé…ç½® 115 Cookiesï¼Œè·³è¿‡ã€‚")
        return
    if not cid_val or str(cid_val) == '0':
        logger.error("  âš ï¸ æœªé…ç½®å¾…æ•´ç†ç›®å½• (CID)ï¼Œè·³è¿‡ã€‚")
        return
    if not enable_organize:
        logger.warning("  âš ï¸ æœªå¼€å¯æ™ºèƒ½æ•´ç†å¼€å…³ï¼Œä»…æ‰«æä¸å¤„ç†ã€‚")
        return

    try:
        save_cid = int(cid_val)
        save_name = str(save_val)

        # 1. å‡†å¤‡ 'æœªè¯†åˆ«' ç›®å½• 
        unidentified_folder_name = "æœªè¯†åˆ«"
        unidentified_cid = None
        try:
            search_res = client.fs_files({'cid': save_cid, 'search_value': unidentified_folder_name, 'limit': 1})
            if search_res.get('data'):
                for item in search_res['data']:
                    if item.get('n') == unidentified_folder_name and (item.get('ico') == 'folder' or not item.get('fid')):
                        unidentified_cid = item.get('cid')
                        break
        except: pass

        if not unidentified_cid:
            try:
                mk_res = client.fs_mkdir(unidentified_folder_name, save_cid)
                if mk_res.get('state'):
                    unidentified_cid = mk_res.get('cid')
            except: pass

        # 2. æ‰«æç›®å½•
        logger.info(f"  ğŸ” æ­£åœ¨æ‰«æç›®å½•: {save_name} ...")
        res = client.fs_files({'cid': save_cid, 'limit': 50, 'o': 'user_ptime', 'asc': 0})

        if not res.get('data'):
            logger.info(f"  ğŸ“‚ [{save_name}] ç›®å½•ä¸ºç©ºã€‚")
            return

        processed_count = 0
        moved_to_unidentified = 0

        for item in res['data']:
            name = item.get('n')
            item_id = item.get('fid') or item.get('cid')
            is_folder = not item.get('fid') # åˆ¤æ–­æ˜¯å¦ä¸ºæ–‡ä»¶å¤¹

            if str(item_id) == str(unidentified_cid) or name == unidentified_folder_name:
                continue

            forced_type = None
            if is_folder:
                try:
                    # å·çœ‹ä¸€çœ¼æ–‡ä»¶å¤¹é‡Œé¢çš„å†…å®¹ (å–å‰20ä¸ªè¶³çŸ£)
                    sub_res = client.fs_files({'cid': item.get('cid'), 'limit': 20})
                    if sub_res.get('data'):
                        for sub_item in sub_res['data']:
                            sub_name = sub_item.get('n', '')
                            # åªè¦åŒ…å« Season XX, S01, EP01, ç¬¬Xå­£ï¼Œå°±æ˜¯ç”µè§†å‰§
                            # ä½ çš„æˆªå›¾é‡Œæ˜¯ "Season 01"ï¼Œè¿™ä¸ªæ­£åˆ™èƒ½å®Œç¾åŒ¹é…
                            if re.search(r'(Season\s?\d+|S\d+|Ep?\d+|ç¬¬\d+å­£)', sub_name, re.IGNORECASE):
                                forced_type = 'tv'
                                logger.info(f"  ğŸ•µï¸â€â™‚ï¸ [ç»“æ„æ¢æµ‹] ç›®å½• '{name}' åŒ…å«å­é¡¹ '{sub_name}' -> åˆ¤å®šä¸º TV")
                                break
                except Exception as e:
                    logger.warning(f"  âš ï¸ ç›®å½•é€è§†å¤±è´¥: {e}")

            # 3. è¯†åˆ« (ä¼ å…¥ forced_type)
            tmdb_id, media_type, title = _identify_media_enhanced(name, forced_media_type=forced_type)
            
            if tmdb_id:
                logger.info(f"  âœ è¯†åˆ«æˆåŠŸ: {name} -> ID:{tmdb_id} ({media_type})")
                try:
                    # 4. å½’ç±»
                    organizer = SmartOrganizer(client, tmdb_id, media_type, title)
                    target_cid = organizer.get_target_cid()
                    if organizer.execute(item, target_cid):
                        processed_count += 1
                except Exception as e:
                    logger.error(f"  âŒ æ•´ç†å‡ºé”™: {e}")
            else:
                # 5. è¯†åˆ«å¤±è´¥ -> ç§»åŠ¨åˆ° 'æœªè¯†åˆ«'
                if unidentified_cid:
                    logger.info(f"  âš ï¸ æ— æ³•è¯†åˆ«: {name} -> ç§»åŠ¨åˆ° 'æœªè¯†åˆ«'")
                    try:
                        client.fs_move(item_id, unidentified_cid)
                        moved_to_unidentified += 1
                    except: pass

        logger.info(f"=== æ‰«æç»“æŸï¼ŒæˆåŠŸå½’ç±» {processed_count} ä¸ªï¼Œç§»å…¥æœªè¯†åˆ« {moved_to_unidentified} ä¸ª ===")

        if processed_count > 0:
            notify_cms_scan()

    except Exception as e:
        logger.error(f"  âš ï¸ 115 æ‰«æä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)